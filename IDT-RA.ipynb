{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Euib_RmfOiT3"
      },
      "source": [
        "## install mujoco-py and D4RL\n",
        "\n",
        "* **Restart Runtime** after running this block to complete D4RL setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAGCHznQs2bI",
        "outputId": "4d4b6fb3-5b6d-414d-fcae-aa3ed19a0f55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease [1,581 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Get:5 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  Packages [1,009 kB]\n",
            "Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,150 kB]\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Get:13 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,669 kB]\n",
            "Hit:14 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Fetched 7,169 kB in 2s (4,000 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "gcc is already the newest version (4:9.3.0-1ubuntu2).\n",
            "gcc set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n",
            "Reading package lists... Done\n",
            "E: Unable to find a source package for mesa\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  binfmt-support libffi-dev libpfm4 libz3-4 libz3-dev llvm llvm-10 llvm-10-dev\n",
            "  llvm-10-runtime llvm-10-tools llvm-runtime python3-pygments python3-yaml\n",
            "Suggested packages:\n",
            "  llvm-10-doc python-pygments-doc ttf-bitstream-vera\n",
            "The following NEW packages will be installed:\n",
            "  binfmt-support libffi-dev libpfm4 libz3-4 libz3-dev llvm llvm-10 llvm-10-dev\n",
            "  llvm-10-runtime llvm-10-tools llvm-dev llvm-runtime python3-pygments\n",
            "  python3-yaml\n",
            "0 upgraded, 14 newly installed, 0 to remove and 25 not upgraded.\n",
            "Need to get 39.7 MB of archives.\n",
            "After this operation, 256 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 python3-yaml amd64 5.3.1-1ubuntu0.1 [136 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 binfmt-support amd64 2.2.0-2 [58.2 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 llvm-10-runtime amd64 1:10.0.0-4ubuntu1 [180 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu focal/universe amd64 llvm-runtime amd64 1:10.0-50~exp1 [2,916 B]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu focal/main amd64 libpfm4 amd64 4.10.1+git20-g7700f49-2 [266 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu focal/universe amd64 llvm-10 amd64 1:10.0.0-4ubuntu1 [5,214 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu focal/universe amd64 llvm amd64 1:10.0-50~exp1 [3,880 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu focal/main amd64 libffi-dev amd64 3.3-4 [57.0 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 python3-pygments all 2.3.1+dfsg-1ubuntu2.2 [579 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu focal/universe amd64 llvm-10-tools amd64 1:10.0.0-4ubuntu1 [317 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu focal/universe amd64 libz3-4 amd64 4.8.7-4build1 [6,792 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu focal/universe amd64 libz3-dev amd64 4.8.7-4build1 [67.5 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu focal/universe amd64 llvm-10-dev amd64 1:10.0.0-4ubuntu1 [26.0 MB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu focal/universe amd64 llvm-dev amd64 1:10.0-50~exp1 [1,856 B]\n",
            "Fetched 39.7 MB in 1s (28.9 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 14.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python3-yaml.\n",
            "(Reading database ... 122518 files and directories currently installed.)\n",
            "Preparing to unpack .../00-python3-yaml_5.3.1-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking python3-yaml (5.3.1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package binfmt-support.\n",
            "Preparing to unpack .../01-binfmt-support_2.2.0-2_amd64.deb ...\n",
            "Unpacking binfmt-support (2.2.0-2) ...\n",
            "Selecting previously unselected package llvm-10-runtime.\n",
            "Preparing to unpack .../02-llvm-10-runtime_1%3a10.0.0-4ubuntu1_amd64.deb ...\n",
            "Unpacking llvm-10-runtime (1:10.0.0-4ubuntu1) ...\n",
            "Selecting previously unselected package llvm-runtime.\n",
            "Preparing to unpack .../03-llvm-runtime_1%3a10.0-50~exp1_amd64.deb ...\n",
            "Unpacking llvm-runtime (1:10.0-50~exp1) ...\n",
            "Selecting previously unselected package libpfm4:amd64.\n",
            "Preparing to unpack .../04-libpfm4_4.10.1+git20-g7700f49-2_amd64.deb ...\n",
            "Unpacking libpfm4:amd64 (4.10.1+git20-g7700f49-2) ...\n",
            "Selecting previously unselected package llvm-10.\n",
            "Preparing to unpack .../05-llvm-10_1%3a10.0.0-4ubuntu1_amd64.deb ...\n",
            "Unpacking llvm-10 (1:10.0.0-4ubuntu1) ...\n",
            "Selecting previously unselected package llvm.\n",
            "Preparing to unpack .../06-llvm_1%3a10.0-50~exp1_amd64.deb ...\n",
            "Unpacking llvm (1:10.0-50~exp1) ...\n",
            "Selecting previously unselected package libffi-dev:amd64.\n",
            "Preparing to unpack .../07-libffi-dev_3.3-4_amd64.deb ...\n",
            "Unpacking libffi-dev:amd64 (3.3-4) ...\n",
            "Selecting previously unselected package python3-pygments.\n",
            "Preparing to unpack .../08-python3-pygments_2.3.1+dfsg-1ubuntu2.2_all.deb ...\n",
            "Unpacking python3-pygments (2.3.1+dfsg-1ubuntu2.2) ...\n",
            "Selecting previously unselected package llvm-10-tools.\n",
            "Preparing to unpack .../09-llvm-10-tools_1%3a10.0.0-4ubuntu1_amd64.deb ...\n",
            "Unpacking llvm-10-tools (1:10.0.0-4ubuntu1) ...\n",
            "Selecting previously unselected package libz3-4:amd64.\n",
            "Preparing to unpack .../10-libz3-4_4.8.7-4build1_amd64.deb ...\n",
            "Unpacking libz3-4:amd64 (4.8.7-4build1) ...\n",
            "Selecting previously unselected package libz3-dev:amd64.\n",
            "Preparing to unpack .../11-libz3-dev_4.8.7-4build1_amd64.deb ...\n",
            "Unpacking libz3-dev:amd64 (4.8.7-4build1) ...\n",
            "Selecting previously unselected package llvm-10-dev.\n",
            "Preparing to unpack .../12-llvm-10-dev_1%3a10.0.0-4ubuntu1_amd64.deb ...\n",
            "Unpacking llvm-10-dev (1:10.0.0-4ubuntu1) ...\n",
            "Selecting previously unselected package llvm-dev.\n",
            "Preparing to unpack .../13-llvm-dev_1%3a10.0-50~exp1_amd64.deb ...\n",
            "Unpacking llvm-dev (1:10.0-50~exp1) ...\n",
            "Setting up python3-yaml (5.3.1-1ubuntu0.1) ...\n",
            "Setting up libffi-dev:amd64 (3.3-4) ...\n",
            "Setting up python3-pygments (2.3.1+dfsg-1ubuntu2.2) ...\n",
            "Setting up libz3-4:amd64 (4.8.7-4build1) ...\n",
            "Setting up libpfm4:amd64 (4.10.1+git20-g7700f49-2) ...\n",
            "Setting up binfmt-support (2.2.0-2) ...\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/binfmt-support.service → /lib/systemd/system/binfmt-support.service.\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up libz3-dev:amd64 (4.8.7-4build1) ...\n",
            "Setting up llvm-10-tools (1:10.0.0-4ubuntu1) ...\n",
            "Setting up llvm-10-runtime (1:10.0.0-4ubuntu1) ...\n",
            "Setting up llvm-runtime (1:10.0-50~exp1) ...\n",
            "Setting up llvm-10 (1:10.0.0-4ubuntu1) ...\n",
            "Setting up llvm-10-dev (1:10.0.0-4ubuntu1) ...\n",
            "Setting up llvm (1:10.0-50~exp1) ...\n",
            "Setting up llvm-dev (1:10.0-50~exp1) ...\n",
            "Processing triggers for systemd (245.4-4ubuntu3.21) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  freeglut3 freeglut3-dev\n",
            "0 upgraded, 2 newly installed, 0 to remove and 25 not upgraded.\n",
            "Need to get 198 kB of archives.\n",
            "After this operation, 1,078 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 freeglut3 amd64 2.8.1-3 [73.6 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 freeglut3-dev amd64 2.8.1-3 [124 kB]\n",
            "Fetched 198 kB in 0s (870 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 2.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package freeglut3:amd64.\n",
            "(Reading database ... 125187 files and directories currently installed.)\n",
            "Preparing to unpack .../freeglut3_2.8.1-3_amd64.deb ...\n",
            "Unpacking freeglut3:amd64 (2.8.1-3) ...\n",
            "Selecting previously unselected package freeglut3-dev:amd64.\n",
            "Preparing to unpack .../freeglut3-dev_2.8.1-3_amd64.deb ...\n",
            "Unpacking freeglut3-dev:amd64 (2.8.1-3) ...\n",
            "Setting up freeglut3:amd64 (2.8.1-3) ...\n",
            "Setting up freeglut3-dev:amd64 (2.8.1-3) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python3-dev is already the newest version (3.8.2-0ubuntu2).\n",
            "python3-dev set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.8ubuntu1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "curl is already the newest version (7.68.0-1ubuntu2.18).\n",
            "git is already the newest version (1:2.25.1-1ubuntu3.11).\n",
            "software-properties-common is already the newest version (0.99.9.11).\n",
            "unzip is already the newest version (6.0-25ubuntu1.1).\n",
            "vim is already the newest version (2:8.1.2269-1ubuntu5.14).\n",
            "wget is already the newest version (1.20.3-1ubuntu2).\n",
            "The following additional packages will be installed:\n",
            "  gir1.2-appindicator3-0.1 gir1.2-atk-1.0 gir1.2-freedesktop\n",
            "  gir1.2-gdkpixbuf-2.0 gir1.2-gtk-3.0 gir1.2-pango-1.0 javascript-common\n",
            "  keyboard-configuration libappindicator3-1 libdbusmenu-glib4\n",
            "  libdbusmenu-gtk3-4 libdrm-dev libegl1-mesa-dev libfontenc-dev libfontenc1\n",
            "  libgles-dev libgles1 libglew2.1 libglfw3 libglvnd-dev libimagequant0\n",
            "  libjs-jquery libjs-sphinxdoc libjs-underscore liblocale-gettext-perl\n",
            "  liblzo2-2 libopengl-dev libosmesa6 libpangoxft-1.0-0 libpciaccess-dev\n",
            "  libpixman-1-dev libudev1 libwayland-bin libwayland-dev libxfont-dev\n",
            "  libxfont2 libxkbfile-dev libxkbfile1 libxrandr-dev libxtst6 mesa-common-dev\n",
            "  python-pip-whl python3-appdirs python3-bcrypt python3-brotli python3-cairo\n",
            "  python3-cffi-backend python3-cpuinfo python3-cryptography python3-decorator\n",
            "  python3-distlib python3-dns python3-filelock python3-gi-cairo python3-gssapi\n",
            "  python3-ifaddr python3-importlib-metadata python3-kerberos python3-lz4\n",
            "  python3-lzo python3-more-itertools python3-nacl python3-nose python3-numpy\n",
            "  python3-olefile python3-opengl python3-paramiko python3-pil python3-rencode\n",
            "  python3-setproctitle python3-uritools python3-virtualenv python3-xdg\n",
            "  python3-zeroconf python3-zipp ssh-askpass udev x11-xkb-utils\n",
            "  x11-xserver-utils x11proto-randr-dev xfonts-base xfonts-encodings\n",
            "  xfonts-utils xserver-common xserver-xorg-core xserver-xorg-input-void\n",
            "  xserver-xorg-video-dummy\n",
            "Suggested packages:\n",
            "  apache2 | lighttpd | httpd indicator-application glew-utils libglfw3-doc\n",
            "  libwayland-doc python-cryptography-doc python3-cryptography-vectors\n",
            "  python-nacl-doc python-nose-doc python-numpy-doc python3-pytest\n",
            "  python3-numpy-dbg python3-tk libgle3 python-pil-doc python3-pil-dbg nickle\n",
            "  cairo-5c xorg-docs-core xfs | xserver openssh-server python3-pyopencl\n",
            "  gstreamer1.0-plugins-base gstreamer1.0-plugins-good\n",
            "  | gstreamer1.0-plugins-ugly | gstreamer1.0-plugins-bad python3-gst-1.0\n",
            "  pulseaudio pulseaudio-utils python3-netifaces cups-client cups-common\n",
            "  cups-filters cups-pdf python3-cups python3-opencv python3-pyinotify\n",
            "  v4l2loopback-dkms python3-uinput xfonts-100dpi | xfonts-75dpi\n",
            "  xfonts-scalable\n",
            "The following NEW packages will be installed:\n",
            "  gir1.2-appindicator3-0.1 gir1.2-atk-1.0 gir1.2-freedesktop\n",
            "  gir1.2-gdkpixbuf-2.0 gir1.2-gtk-3.0 gir1.2-pango-1.0 javascript-common\n",
            "  keyboard-configuration libappindicator3-1 libdbusmenu-glib4\n",
            "  libdbusmenu-gtk3-4 libdrm-dev libegl1-mesa-dev libfontenc-dev libfontenc1\n",
            "  libgl1-mesa-dev libgl1-mesa-glx libgles-dev libgles1 libglew-dev libglew2.1\n",
            "  libglfw3 libglfw3-dev libglvnd-dev libimagequant0 libjs-jquery\n",
            "  libjs-sphinxdoc libjs-underscore liblocale-gettext-perl liblzo2-2\n",
            "  libopengl-dev libosmesa6 libosmesa6-dev libpangoxft-1.0-0 libpciaccess-dev\n",
            "  libpixman-1-dev libwayland-bin libwayland-dev libxfont-dev libxfont2\n",
            "  libxkbfile-dev libxkbfile1 libxrandr-dev libxtst6 mesa-common-dev net-tools\n",
            "  patchelf python-pip-whl python3-appdirs python3-bcrypt python3-brotli\n",
            "  python3-cairo python3-cffi-backend python3-cpuinfo python3-cryptography\n",
            "  python3-decorator python3-distlib python3-dns python3-filelock\n",
            "  python3-gi-cairo python3-gssapi python3-ifaddr python3-importlib-metadata\n",
            "  python3-kerberos python3-lz4 python3-lzo python3-more-itertools python3-nacl\n",
            "  python3-nose python3-numpy python3-olefile python3-opengl python3-paramiko\n",
            "  python3-pil python3-rencode python3-setproctitle python3-uritools\n",
            "  python3-virtualenv python3-xdg python3-zeroconf python3-zipp ssh-askpass\n",
            "  udev virtualenv x11-xkb-utils x11-xserver-utils x11proto-randr-dev\n",
            "  xfonts-base xfonts-encodings xfonts-utils xpra xserver-common\n",
            "  xserver-xorg-core xserver-xorg-dev xserver-xorg-input-void\n",
            "  xserver-xorg-video-dummy\n",
            "The following packages will be upgraded:\n",
            "  libudev1\n",
            "1 upgraded, 96 newly installed, 0 to remove and 24 not upgraded.\n",
            "Need to get 27.2 MB of archives.\n",
            "After this operation, 98.4 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/main amd64 liblocale-gettext-perl amd64 1.07-4 [17.1 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/main amd64 keyboard-configuration all 1.194ubuntu3 [190 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libudev1 amd64 245.4-4ubuntu3.21 [75.9 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu focal/main amd64 python3-cffi-backend amd64 1.14.0-1build1 [68.7 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu focal/main amd64 python3-nacl amd64 1.3.0-5 [49.0 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 udev amd64 245.4-4ubuntu3.21 [1,366 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu focal/main amd64 gir1.2-atk-1.0 amd64 2.35.1-1ubuntu2 [18.2 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 gir1.2-freedesktop amd64 1.64.1-1~ubuntu20.04.1 [19.2 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 gir1.2-gdkpixbuf-2.0 amd64 2.40.0+dfsg-3ubuntu0.4 [8,272 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu focal/main amd64 libpangoxft-1.0-0 amd64 1.44.7-2ubuntu4 [18.0 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu focal/main amd64 gir1.2-pango-1.0 amd64 1.44.7-2ubuntu4 [26.6 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 gir1.2-gtk-3.0 amd64 3.24.20-0ubuntu1.1 [196 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu focal/main amd64 libdbusmenu-glib4 amd64 16.04.1+18.10.20180917-0ubuntu6 [41.2 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu focal/main amd64 libdbusmenu-gtk3-4 amd64 16.04.1+18.10.20180917-0ubuntu6 [27.7 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu focal/main amd64 libappindicator3-1 amd64 12.10.1+20.04.20200408.1-0ubuntu1 [22.9 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu focal/main amd64 gir1.2-appindicator3-0.1 amd64 12.10.1+20.04.20200408.1-0ubuntu1 [3,448 B]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu focal/main amd64 javascript-common all 11 [6,066 B]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu focal/main amd64 libpciaccess-dev amd64 0.16-0ubuntu1 [20.3 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libdrm-dev amd64 2.4.107-8ubuntu1~20.04.2 [131 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libgles1 amd64 1.3.2-1~ubuntu0.20.04.2 [10.3 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libgles-dev amd64 1.3.2-1~ubuntu0.20.04.2 [47.9 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libopengl-dev amd64 1.3.2-1~ubuntu0.20.04.2 [3,584 B]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libglvnd-dev amd64 1.3.2-1~ubuntu0.20.04.2 [11.6 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libegl1-mesa-dev amd64 21.2.6-0ubuntu0.1~20.04.2 [7,760 B]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu focal/main amd64 libfontenc1 amd64 1:1.1.4-0ubuntu1 [14.0 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu focal/main amd64 libfontenc-dev amd64 1:1.1.4-0ubuntu1 [14.3 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libgl1-mesa-glx amd64 21.2.6-0ubuntu0.1~20.04.2 [5,536 B]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libgl1-mesa-dev amd64 21.2.6-0ubuntu0.1~20.04.2 [6,420 B]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu focal/universe amd64 libglew2.1 amd64 2.1.0-4 [155 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu focal/universe amd64 libglew-dev amd64 2.1.0-4 [134 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu focal/universe amd64 libglfw3 amd64 3.3.2-1 [73.6 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu focal/universe amd64 libglfw3-dev amd64 3.3.2-1 [39.6 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu focal/main amd64 libimagequant0 amd64 2.12.2-1.1 [31.4 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu focal/main amd64 libjs-jquery all 3.3.1~dfsg-3 [329 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libjs-underscore all 1.9.1~dfsg-1ubuntu0.20.04.1 [99.5 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu focal/main amd64 libjs-sphinxdoc all 1.8.5-7ubuntu3 [97.1 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu focal/main amd64 liblzo2-2 amd64 2.10-2 [50.8 kB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libpixman-1-dev amd64 0.38.4-0ubuntu2.1 [243 kB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu focal/main amd64 libxfont2 amd64 1:2.0.3-1 [91.7 kB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu focal/main amd64 libxfont-dev amd64 1:2.0.3-1 [118 kB]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu focal/main amd64 libxkbfile1 amd64 1:1.1.0-1 [65.3 kB]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu focal/main amd64 libxkbfile-dev amd64 1:1.1.0-1 [74.7 kB]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu focal/main amd64 x11proto-randr-dev all 2019.2-1ubuntu1 [2,620 B]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu focal/main amd64 libxrandr-dev amd64 2:1.5.2-0ubuntu1 [25.0 kB]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu focal/main amd64 libxtst6 amd64 2:1.2.3-1 [12.8 kB]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 mesa-common-dev amd64 21.2.6-0ubuntu0.1~20.04.2 [1,504 kB]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu focal/main amd64 net-tools amd64 1.60+git20180626.aebd88e-1ubuntu1 [196 kB]\n",
            "Get:48 http://archive.ubuntu.com/ubuntu focal/universe amd64 patchelf amd64 0.10-2build1 [53.4 kB]\n",
            "Get:49 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python-pip-whl all 20.0.2-5ubuntu1.8 [1,805 kB]\n",
            "Get:50 http://archive.ubuntu.com/ubuntu focal/main amd64 python3-appdirs all 1.4.3-2.1 [10.8 kB]\n",
            "Get:51 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python3-brotli amd64 1.0.7-6ubuntu0.1 [271 kB]\n",
            "Get:52 http://archive.ubuntu.com/ubuntu focal/main amd64 python3-cairo amd64 1.16.2-2ubuntu2 [56.8 kB]\n",
            "Get:53 http://archive.ubuntu.com/ubuntu focal/universe amd64 python3-cpuinfo all 5.0.0-2 [17.3 kB]\n",
            "Get:54 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 python3-cryptography amd64 2.8-3ubuntu0.1 [211 kB]\n",
            "Get:55 http://archive.ubuntu.com/ubuntu focal/main amd64 python3-decorator all 4.4.2-0ubuntu1 [10.3 kB]\n",
            "Get:56 http://archive.ubuntu.com/ubuntu focal/universe amd64 python3-distlib all 0.3.0-1 [116 kB]\n",
            "Get:57 http://archive.ubuntu.com/ubuntu focal/universe amd64 python3-dns all 3.2.1-1 [25.6 kB]\n",
            "Get:58 http://archive.ubuntu.com/ubuntu focal/universe amd64 python3-filelock all 3.0.12-2 [7,948 B]\n",
            "Get:59 http://archive.ubuntu.com/ubuntu focal/main amd64 python3-gi-cairo amd64 3.36.0-1 [7,664 B]\n",
            "Get:60 http://archive.ubuntu.com/ubuntu focal/universe amd64 python3-gssapi amd64 1.6.1-1build1 [410 kB]\n",
            "Get:61 http://archive.ubuntu.com/ubuntu focal/universe amd64 python3-ifaddr all 0.1.6-1 [7,492 B]\n",
            "Get:62 http://archive.ubuntu.com/ubuntu focal/main amd64 python3-more-itertools all 4.2.0-1build1 [39.4 kB]\n",
            "Get:63 http://archive.ubuntu.com/ubuntu focal/main amd64 python3-zipp all 1.0.0-1 [5,312 B]\n",
            "Get:64 http://archive.ubuntu.com/ubuntu focal/main amd64 python3-importlib-metadata all 1.5.0-1 [9,992 B]\n",
            "Get:65 http://archive.ubuntu.com/ubuntu focal/universe amd64 python3-kerberos amd64 1.1.14-3.1build1 [22.6 kB]\n",
            "Get:66 http://archive.ubuntu.com/ubuntu focal/universe amd64 python3-lz4 amd64 3.0.2+dfsg-1build1 [31.2 kB]\n",
            "Get:67 http://archive.ubuntu.com/ubuntu focal/universe amd64 python3-lzo amd64 1.12-3build2 [7,488 B]\n",
            "Get:68 http://archive.ubuntu.com/ubuntu focal/universe amd64 python3-nose all 1.3.7-5 [116 kB]\n",
            "Get:69 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 python3-numpy amd64 1:1.17.4-5ubuntu3.1 [2,724 kB]\n",
            "Get:70 http://archive.ubuntu.com/ubuntu focal/main amd64 python3-olefile all 0.46-2 [33.7 kB]\n",
            "Get:71 http://archive.ubuntu.com/ubuntu focal/universe amd64 python3-opengl all 3.1.0+dfsg-2build1 [486 kB]\n",
            "Get:72 http://archive.ubuntu.com/ubuntu focal/main amd64 python3-bcrypt amd64 3.1.7-2ubuntu1 [30.4 kB]\n",
            "Get:73 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 python3-paramiko all 2.6.0-2ubuntu0.1 [122 kB]\n",
            "Get:74 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 python3-pil amd64 7.0.0-4ubuntu0.7 [366 kB]\n",
            "Get:75 http://archive.ubuntu.com/ubuntu focal/universe amd64 python3-rencode amd64 1.0.6-1build1 [45.9 kB]\n",
            "Get:76 http://archive.ubuntu.com/ubuntu focal/universe amd64 python3-uritools all 3.0.0-1 [28.7 kB]\n",
            "Get:77 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python3-virtualenv all 20.0.17-1ubuntu0.4 [62.7 kB]\n",
            "Get:78 http://archive.ubuntu.com/ubuntu focal/main amd64 python3-xdg all 0.26-1ubuntu1 [36.1 kB]\n",
            "Get:79 http://archive.ubuntu.com/ubuntu focal/universe amd64 python3-zeroconf all 0.24.4-0ubuntu1 [40.6 kB]\n",
            "Get:80 http://archive.ubuntu.com/ubuntu focal/universe amd64 ssh-askpass amd64 1:1.2.4.1-10 [26.3 kB]\n",
            "Get:81 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 virtualenv all 20.0.17-1ubuntu0.4 [2,144 B]\n",
            "Get:82 http://archive.ubuntu.com/ubuntu focal/main amd64 x11-xkb-utils amd64 7.7+5 [158 kB]\n",
            "Get:83 http://archive.ubuntu.com/ubuntu focal/main amd64 x11-xserver-utils amd64 7.7+8 [162 kB]\n",
            "Get:84 http://archive.ubuntu.com/ubuntu focal/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu1 [573 kB]\n",
            "Get:85 http://archive.ubuntu.com/ubuntu focal/main amd64 xfonts-utils amd64 1:7.7+6 [91.5 kB]\n",
            "Get:86 http://archive.ubuntu.com/ubuntu focal/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n",
            "Get:87 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 xserver-common all 2:1.20.13-1ubuntu1~20.04.8 [27.2 kB]\n",
            "Get:88 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 xserver-xorg-core amd64 2:1.20.13-1ubuntu1~20.04.8 [1,340 kB]\n",
            "Get:89 http://archive.ubuntu.com/ubuntu focal/universe amd64 xserver-xorg-input-void amd64 1:1.4.1-1build3 [6,806 B]\n",
            "Get:90 http://archive.ubuntu.com/ubuntu focal/main amd64 xserver-xorg-video-dummy amd64 1:0.3.8-1build3 [8,884 B]\n",
            "Get:91 http://archive.ubuntu.com/ubuntu focal/universe amd64 xpra amd64 3.0.6+dfsg1-1build1 [2,531 kB]\n",
            "Get:92 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 xserver-xorg-dev amd64 2:1.20.13-1ubuntu1~20.04.8 [201 kB]\n",
            "Get:93 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libosmesa6 amd64 21.2.6-0ubuntu0.1~20.04.2 [3,054 kB]\n",
            "Get:94 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libosmesa6-dev amd64 21.2.6-0ubuntu0.1~20.04.2 [8,844 B]\n",
            "Get:95 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libwayland-bin amd64 1.18.0-1ubuntu0.1 [20.2 kB]\n",
            "Get:96 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libwayland-dev amd64 1.18.0-1ubuntu0.1 [64.6 kB]\n",
            "Get:97 http://archive.ubuntu.com/ubuntu focal/main amd64 python3-setproctitle amd64 1.1.10-1ubuntu1 [15.1 kB]\n",
            "Fetched 27.2 MB in 3s (8,341 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 97.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package liblocale-gettext-perl.\n",
            "(Reading database ... 125209 files and directories currently installed.)\n",
            "Preparing to unpack .../liblocale-gettext-perl_1.07-4_amd64.deb ...\n",
            "Unpacking liblocale-gettext-perl (1.07-4) ...\n",
            "Selecting previously unselected package keyboard-configuration.\n",
            "Preparing to unpack .../keyboard-configuration_1.194ubuntu3_all.deb ...\n",
            "Unpacking keyboard-configuration (1.194ubuntu3) ...\n",
            "Preparing to unpack .../libudev1_245.4-4ubuntu3.21_amd64.deb ...\n",
            "Unpacking libudev1:amd64 (245.4-4ubuntu3.21) over (245.4-4ubuntu3.19) ...\n",
            "Setting up libudev1:amd64 (245.4-4ubuntu3.21) ...\n",
            "Selecting previously unselected package python3-cffi-backend.\n",
            "(Reading database ... 125243 files and directories currently installed.)\n",
            "Preparing to unpack .../00-python3-cffi-backend_1.14.0-1build1_amd64.deb ...\n",
            "Unpacking python3-cffi-backend (1.14.0-1build1) ...\n",
            "Selecting previously unselected package python3-nacl.\n",
            "Preparing to unpack .../01-python3-nacl_1.3.0-5_amd64.deb ...\n",
            "Unpacking python3-nacl (1.3.0-5) ...\n",
            "Selecting previously unselected package udev.\n",
            "Preparing to unpack .../02-udev_245.4-4ubuntu3.21_amd64.deb ...\n",
            "Unpacking udev (245.4-4ubuntu3.21) ...\n",
            "Selecting previously unselected package gir1.2-atk-1.0:amd64.\n",
            "Preparing to unpack .../03-gir1.2-atk-1.0_2.35.1-1ubuntu2_amd64.deb ...\n",
            "Unpacking gir1.2-atk-1.0:amd64 (2.35.1-1ubuntu2) ...\n",
            "Selecting previously unselected package gir1.2-freedesktop:amd64.\n",
            "Preparing to unpack .../04-gir1.2-freedesktop_1.64.1-1~ubuntu20.04.1_amd64.deb ...\n",
            "Unpacking gir1.2-freedesktop:amd64 (1.64.1-1~ubuntu20.04.1) ...\n",
            "Selecting previously unselected package gir1.2-gdkpixbuf-2.0:amd64.\n",
            "Preparing to unpack .../05-gir1.2-gdkpixbuf-2.0_2.40.0+dfsg-3ubuntu0.4_amd64.deb ...\n",
            "Unpacking gir1.2-gdkpixbuf-2.0:amd64 (2.40.0+dfsg-3ubuntu0.4) ...\n",
            "Selecting previously unselected package libpangoxft-1.0-0:amd64.\n",
            "Preparing to unpack .../06-libpangoxft-1.0-0_1.44.7-2ubuntu4_amd64.deb ...\n",
            "Unpacking libpangoxft-1.0-0:amd64 (1.44.7-2ubuntu4) ...\n",
            "Selecting previously unselected package gir1.2-pango-1.0:amd64.\n",
            "Preparing to unpack .../07-gir1.2-pango-1.0_1.44.7-2ubuntu4_amd64.deb ...\n",
            "Unpacking gir1.2-pango-1.0:amd64 (1.44.7-2ubuntu4) ...\n",
            "Selecting previously unselected package gir1.2-gtk-3.0:amd64.\n",
            "Preparing to unpack .../08-gir1.2-gtk-3.0_3.24.20-0ubuntu1.1_amd64.deb ...\n",
            "Unpacking gir1.2-gtk-3.0:amd64 (3.24.20-0ubuntu1.1) ...\n",
            "Selecting previously unselected package libdbusmenu-glib4:amd64.\n",
            "Preparing to unpack .../09-libdbusmenu-glib4_16.04.1+18.10.20180917-0ubuntu6_amd64.deb ...\n",
            "Unpacking libdbusmenu-glib4:amd64 (16.04.1+18.10.20180917-0ubuntu6) ...\n",
            "Selecting previously unselected package libdbusmenu-gtk3-4:amd64.\n",
            "Preparing to unpack .../10-libdbusmenu-gtk3-4_16.04.1+18.10.20180917-0ubuntu6_amd64.deb ...\n",
            "Unpacking libdbusmenu-gtk3-4:amd64 (16.04.1+18.10.20180917-0ubuntu6) ...\n",
            "Selecting previously unselected package libappindicator3-1.\n",
            "Preparing to unpack .../11-libappindicator3-1_12.10.1+20.04.20200408.1-0ubuntu1_amd64.deb ...\n",
            "Unpacking libappindicator3-1 (12.10.1+20.04.20200408.1-0ubuntu1) ...\n",
            "Selecting previously unselected package gir1.2-appindicator3-0.1.\n",
            "Preparing to unpack .../12-gir1.2-appindicator3-0.1_12.10.1+20.04.20200408.1-0ubuntu1_amd64.deb ...\n",
            "Unpacking gir1.2-appindicator3-0.1 (12.10.1+20.04.20200408.1-0ubuntu1) ...\n",
            "Selecting previously unselected package javascript-common.\n",
            "Preparing to unpack .../13-javascript-common_11_all.deb ...\n",
            "Unpacking javascript-common (11) ...\n",
            "Selecting previously unselected package libpciaccess-dev:amd64.\n",
            "Preparing to unpack .../14-libpciaccess-dev_0.16-0ubuntu1_amd64.deb ...\n",
            "Unpacking libpciaccess-dev:amd64 (0.16-0ubuntu1) ...\n",
            "Selecting previously unselected package libdrm-dev:amd64.\n",
            "Preparing to unpack .../15-libdrm-dev_2.4.107-8ubuntu1~20.04.2_amd64.deb ...\n",
            "Unpacking libdrm-dev:amd64 (2.4.107-8ubuntu1~20.04.2) ...\n",
            "Selecting previously unselected package libgles1:amd64.\n",
            "Preparing to unpack .../16-libgles1_1.3.2-1~ubuntu0.20.04.2_amd64.deb ...\n",
            "Unpacking libgles1:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\n",
            "Selecting previously unselected package libgles-dev:amd64.\n",
            "Preparing to unpack .../17-libgles-dev_1.3.2-1~ubuntu0.20.04.2_amd64.deb ...\n",
            "Unpacking libgles-dev:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\n",
            "Selecting previously unselected package libopengl-dev:amd64.\n",
            "Preparing to unpack .../18-libopengl-dev_1.3.2-1~ubuntu0.20.04.2_amd64.deb ...\n",
            "Unpacking libopengl-dev:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\n",
            "Selecting previously unselected package libglvnd-dev:amd64.\n",
            "Preparing to unpack .../19-libglvnd-dev_1.3.2-1~ubuntu0.20.04.2_amd64.deb ...\n",
            "Unpacking libglvnd-dev:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\n",
            "Selecting previously unselected package libegl1-mesa-dev:amd64.\n",
            "Preparing to unpack .../20-libegl1-mesa-dev_21.2.6-0ubuntu0.1~20.04.2_amd64.deb ...\n",
            "Unpacking libegl1-mesa-dev:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "Preparing to unpack .../21-libfontenc1_1%3a1.1.4-0ubuntu1_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-0ubuntu1) ...\n",
            "Selecting previously unselected package libfontenc-dev:amd64.\n",
            "Preparing to unpack .../22-libfontenc-dev_1%3a1.1.4-0ubuntu1_amd64.deb ...\n",
            "Unpacking libfontenc-dev:amd64 (1:1.1.4-0ubuntu1) ...\n",
            "Selecting previously unselected package libgl1-mesa-glx:amd64.\n",
            "Preparing to unpack .../23-libgl1-mesa-glx_21.2.6-0ubuntu0.1~20.04.2_amd64.deb ...\n",
            "Unpacking libgl1-mesa-glx:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\n",
            "Selecting previously unselected package libgl1-mesa-dev:amd64.\n",
            "Preparing to unpack .../24-libgl1-mesa-dev_21.2.6-0ubuntu0.1~20.04.2_amd64.deb ...\n",
            "Unpacking libgl1-mesa-dev:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\n",
            "Selecting previously unselected package libglew2.1:amd64.\n",
            "Preparing to unpack .../25-libglew2.1_2.1.0-4_amd64.deb ...\n",
            "Unpacking libglew2.1:amd64 (2.1.0-4) ...\n",
            "Selecting previously unselected package libglew-dev:amd64.\n",
            "Preparing to unpack .../26-libglew-dev_2.1.0-4_amd64.deb ...\n",
            "Unpacking libglew-dev:amd64 (2.1.0-4) ...\n",
            "Selecting previously unselected package libglfw3:amd64.\n",
            "Preparing to unpack .../27-libglfw3_3.3.2-1_amd64.deb ...\n",
            "Unpacking libglfw3:amd64 (3.3.2-1) ...\n",
            "Selecting previously unselected package libglfw3-dev:amd64.\n",
            "Preparing to unpack .../28-libglfw3-dev_3.3.2-1_amd64.deb ...\n",
            "Unpacking libglfw3-dev:amd64 (3.3.2-1) ...\n",
            "Selecting previously unselected package libimagequant0:amd64.\n",
            "Preparing to unpack .../29-libimagequant0_2.12.2-1.1_amd64.deb ...\n",
            "Unpacking libimagequant0:amd64 (2.12.2-1.1) ...\n",
            "Selecting previously unselected package libjs-jquery.\n",
            "Preparing to unpack .../30-libjs-jquery_3.3.1~dfsg-3_all.deb ...\n",
            "Unpacking libjs-jquery (3.3.1~dfsg-3) ...\n",
            "Selecting previously unselected package libjs-underscore.\n",
            "Preparing to unpack .../31-libjs-underscore_1.9.1~dfsg-1ubuntu0.20.04.1_all.deb ...\n",
            "Unpacking libjs-underscore (1.9.1~dfsg-1ubuntu0.20.04.1) ...\n",
            "Selecting previously unselected package libjs-sphinxdoc.\n",
            "Preparing to unpack .../32-libjs-sphinxdoc_1.8.5-7ubuntu3_all.deb ...\n",
            "Unpacking libjs-sphinxdoc (1.8.5-7ubuntu3) ...\n",
            "Selecting previously unselected package liblzo2-2:amd64.\n",
            "Preparing to unpack .../33-liblzo2-2_2.10-2_amd64.deb ...\n",
            "Unpacking liblzo2-2:amd64 (2.10-2) ...\n",
            "Selecting previously unselected package libpixman-1-dev:amd64.\n",
            "Preparing to unpack .../34-libpixman-1-dev_0.38.4-0ubuntu2.1_amd64.deb ...\n",
            "Unpacking libpixman-1-dev:amd64 (0.38.4-0ubuntu2.1) ...\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "Preparing to unpack .../35-libxfont2_1%3a2.0.3-1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.3-1) ...\n",
            "Selecting previously unselected package libxfont-dev.\n",
            "Preparing to unpack .../36-libxfont-dev_1%3a2.0.3-1_amd64.deb ...\n",
            "Unpacking libxfont-dev (1:2.0.3-1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../37-libxkbfile1_1%3a1.1.0-1_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1) ...\n",
            "Selecting previously unselected package libxkbfile-dev:amd64.\n",
            "Preparing to unpack .../38-libxkbfile-dev_1%3a1.1.0-1_amd64.deb ...\n",
            "Unpacking libxkbfile-dev:amd64 (1:1.1.0-1) ...\n",
            "Selecting previously unselected package x11proto-randr-dev.\n",
            "Preparing to unpack .../39-x11proto-randr-dev_2019.2-1ubuntu1_all.deb ...\n",
            "Unpacking x11proto-randr-dev (2019.2-1ubuntu1) ...\n",
            "Selecting previously unselected package libxrandr-dev:amd64.\n",
            "Preparing to unpack .../40-libxrandr-dev_2%3a1.5.2-0ubuntu1_amd64.deb ...\n",
            "Unpacking libxrandr-dev:amd64 (2:1.5.2-0ubuntu1) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../41-libxtst6_2%3a1.2.3-1_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1) ...\n",
            "Selecting previously unselected package mesa-common-dev:amd64.\n",
            "Preparing to unpack .../42-mesa-common-dev_21.2.6-0ubuntu0.1~20.04.2_amd64.deb ...\n",
            "Unpacking mesa-common-dev:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\n",
            "Selecting previously unselected package net-tools.\n",
            "Preparing to unpack .../43-net-tools_1.60+git20180626.aebd88e-1ubuntu1_amd64.deb ...\n",
            "Unpacking net-tools (1.60+git20180626.aebd88e-1ubuntu1) ...\n",
            "Selecting previously unselected package patchelf.\n",
            "Preparing to unpack .../44-patchelf_0.10-2build1_amd64.deb ...\n",
            "Unpacking patchelf (0.10-2build1) ...\n",
            "Selecting previously unselected package python-pip-whl.\n",
            "Preparing to unpack .../45-python-pip-whl_20.0.2-5ubuntu1.8_all.deb ...\n",
            "Unpacking python-pip-whl (20.0.2-5ubuntu1.8) ...\n",
            "Selecting previously unselected package python3-appdirs.\n",
            "Preparing to unpack .../46-python3-appdirs_1.4.3-2.1_all.deb ...\n",
            "Unpacking python3-appdirs (1.4.3-2.1) ...\n",
            "Selecting previously unselected package python3-brotli.\n",
            "Preparing to unpack .../47-python3-brotli_1.0.7-6ubuntu0.1_amd64.deb ...\n",
            "Unpacking python3-brotli (1.0.7-6ubuntu0.1) ...\n",
            "Selecting previously unselected package python3-cairo:amd64.\n",
            "Preparing to unpack .../48-python3-cairo_1.16.2-2ubuntu2_amd64.deb ...\n",
            "Unpacking python3-cairo:amd64 (1.16.2-2ubuntu2) ...\n",
            "Selecting previously unselected package python3-cpuinfo.\n",
            "Preparing to unpack .../49-python3-cpuinfo_5.0.0-2_all.deb ...\n",
            "Unpacking python3-cpuinfo (5.0.0-2) ...\n",
            "Selecting previously unselected package python3-cryptography.\n",
            "Preparing to unpack .../50-python3-cryptography_2.8-3ubuntu0.1_amd64.deb ...\n",
            "Unpacking python3-cryptography (2.8-3ubuntu0.1) ...\n",
            "Selecting previously unselected package python3-decorator.\n",
            "Preparing to unpack .../51-python3-decorator_4.4.2-0ubuntu1_all.deb ...\n",
            "Unpacking python3-decorator (4.4.2-0ubuntu1) ...\n",
            "Selecting previously unselected package python3-distlib.\n",
            "Preparing to unpack .../52-python3-distlib_0.3.0-1_all.deb ...\n",
            "Unpacking python3-distlib (0.3.0-1) ...\n",
            "Selecting previously unselected package python3-dns.\n",
            "Preparing to unpack .../53-python3-dns_3.2.1-1_all.deb ...\n",
            "Unpacking python3-dns (3.2.1-1) ...\n",
            "Selecting previously unselected package python3-filelock.\n",
            "Preparing to unpack .../54-python3-filelock_3.0.12-2_all.deb ...\n",
            "Unpacking python3-filelock (3.0.12-2) ...\n",
            "Selecting previously unselected package python3-gi-cairo.\n",
            "Preparing to unpack .../55-python3-gi-cairo_3.36.0-1_amd64.deb ...\n",
            "Unpacking python3-gi-cairo (3.36.0-1) ...\n",
            "Selecting previously unselected package python3-gssapi.\n",
            "Preparing to unpack .../56-python3-gssapi_1.6.1-1build1_amd64.deb ...\n",
            "Unpacking python3-gssapi (1.6.1-1build1) ...\n",
            "Selecting previously unselected package python3-ifaddr.\n",
            "Preparing to unpack .../57-python3-ifaddr_0.1.6-1_all.deb ...\n",
            "Unpacking python3-ifaddr (0.1.6-1) ...\n",
            "Selecting previously unselected package python3-more-itertools.\n",
            "Preparing to unpack .../58-python3-more-itertools_4.2.0-1build1_all.deb ...\n",
            "Unpacking python3-more-itertools (4.2.0-1build1) ...\n",
            "Selecting previously unselected package python3-zipp.\n",
            "Preparing to unpack .../59-python3-zipp_1.0.0-1_all.deb ...\n",
            "Unpacking python3-zipp (1.0.0-1) ...\n",
            "Selecting previously unselected package python3-importlib-metadata.\n",
            "Preparing to unpack .../60-python3-importlib-metadata_1.5.0-1_all.deb ...\n",
            "Unpacking python3-importlib-metadata (1.5.0-1) ...\n",
            "Selecting previously unselected package python3-kerberos.\n",
            "Preparing to unpack .../61-python3-kerberos_1.1.14-3.1build1_amd64.deb ...\n",
            "Unpacking python3-kerberos (1.1.14-3.1build1) ...\n",
            "Selecting previously unselected package python3-lz4.\n",
            "Preparing to unpack .../62-python3-lz4_3.0.2+dfsg-1build1_amd64.deb ...\n",
            "Unpacking python3-lz4 (3.0.2+dfsg-1build1) ...\n",
            "Selecting previously unselected package python3-lzo.\n",
            "Preparing to unpack .../63-python3-lzo_1.12-3build2_amd64.deb ...\n",
            "Unpacking python3-lzo (1.12-3build2) ...\n",
            "Selecting previously unselected package python3-nose.\n",
            "Preparing to unpack .../64-python3-nose_1.3.7-5_all.deb ...\n",
            "Unpacking python3-nose (1.3.7-5) ...\n",
            "Selecting previously unselected package python3-numpy.\n",
            "Preparing to unpack .../65-python3-numpy_1%3a1.17.4-5ubuntu3.1_amd64.deb ...\n",
            "Unpacking python3-numpy (1:1.17.4-5ubuntu3.1) ...\n",
            "Selecting previously unselected package python3-olefile.\n",
            "Preparing to unpack .../66-python3-olefile_0.46-2_all.deb ...\n",
            "Unpacking python3-olefile (0.46-2) ...\n",
            "Selecting previously unselected package python3-opengl.\n",
            "Preparing to unpack .../67-python3-opengl_3.1.0+dfsg-2build1_all.deb ...\n",
            "Unpacking python3-opengl (3.1.0+dfsg-2build1) ...\n",
            "Selecting previously unselected package python3-bcrypt.\n",
            "Preparing to unpack .../68-python3-bcrypt_3.1.7-2ubuntu1_amd64.deb ...\n",
            "Unpacking python3-bcrypt (3.1.7-2ubuntu1) ...\n",
            "Selecting previously unselected package python3-paramiko.\n",
            "Preparing to unpack .../69-python3-paramiko_2.6.0-2ubuntu0.1_all.deb ...\n",
            "Unpacking python3-paramiko (2.6.0-2ubuntu0.1) ...\n",
            "Selecting previously unselected package python3-pil:amd64.\n",
            "Preparing to unpack .../70-python3-pil_7.0.0-4ubuntu0.7_amd64.deb ...\n",
            "Unpacking python3-pil:amd64 (7.0.0-4ubuntu0.7) ...\n",
            "Selecting previously unselected package python3-rencode.\n",
            "Preparing to unpack .../71-python3-rencode_1.0.6-1build1_amd64.deb ...\n",
            "Unpacking python3-rencode (1.0.6-1build1) ...\n",
            "Selecting previously unselected package python3-uritools.\n",
            "Preparing to unpack .../72-python3-uritools_3.0.0-1_all.deb ...\n",
            "Unpacking python3-uritools (3.0.0-1) ...\n",
            "Selecting previously unselected package python3-virtualenv.\n",
            "Preparing to unpack .../73-python3-virtualenv_20.0.17-1ubuntu0.4_all.deb ...\n",
            "Unpacking python3-virtualenv (20.0.17-1ubuntu0.4) ...\n",
            "Selecting previously unselected package python3-xdg.\n",
            "Preparing to unpack .../74-python3-xdg_0.26-1ubuntu1_all.deb ...\n",
            "Unpacking python3-xdg (0.26-1ubuntu1) ...\n",
            "Selecting previously unselected package python3-zeroconf.\n",
            "Preparing to unpack .../75-python3-zeroconf_0.24.4-0ubuntu1_all.deb ...\n",
            "Unpacking python3-zeroconf (0.24.4-0ubuntu1) ...\n",
            "Selecting previously unselected package ssh-askpass.\n",
            "Preparing to unpack .../76-ssh-askpass_1%3a1.2.4.1-10_amd64.deb ...\n",
            "Unpacking ssh-askpass (1:1.2.4.1-10) ...\n",
            "Selecting previously unselected package virtualenv.\n",
            "Preparing to unpack .../77-virtualenv_20.0.17-1ubuntu0.4_all.deb ...\n",
            "Unpacking virtualenv (20.0.17-1ubuntu0.4) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../78-x11-xkb-utils_7.7+5_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+5) ...\n",
            "Selecting previously unselected package x11-xserver-utils.\n",
            "Preparing to unpack .../79-x11-xserver-utils_7.7+8_amd64.deb ...\n",
            "Unpacking x11-xserver-utils (7.7+8) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../80-xfonts-encodings_1%3a1.0.5-0ubuntu1_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu1) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../81-xfonts-utils_1%3a7.7+6_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6) ...\n",
            "Selecting previously unselected package xfonts-base.\n",
            "Preparing to unpack .../82-xfonts-base_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-base (1:1.0.5) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../83-xserver-common_2%3a1.20.13-1ubuntu1~20.04.8_all.deb ...\n",
            "Unpacking xserver-common (2:1.20.13-1ubuntu1~20.04.8) ...\n",
            "Selecting previously unselected package xserver-xorg-core.\n",
            "Preparing to unpack .../84-xserver-xorg-core_2%3a1.20.13-1ubuntu1~20.04.8_amd64.deb ...\n",
            "Unpacking xserver-xorg-core (2:1.20.13-1ubuntu1~20.04.8) ...\n",
            "Selecting previously unselected package xserver-xorg-input-void.\n",
            "Preparing to unpack .../85-xserver-xorg-input-void_1%3a1.4.1-1build3_amd64.deb ...\n",
            "Unpacking xserver-xorg-input-void (1:1.4.1-1build3) ...\n",
            "Selecting previously unselected package xserver-xorg-video-dummy.\n",
            "Preparing to unpack .../86-xserver-xorg-video-dummy_1%3a0.3.8-1build3_amd64.deb ...\n",
            "Unpacking xserver-xorg-video-dummy (1:0.3.8-1build3) ...\n",
            "Selecting previously unselected package xpra.\n",
            "Preparing to unpack .../87-xpra_3.0.6+dfsg1-1build1_amd64.deb ...\n",
            "Unpacking xpra (3.0.6+dfsg1-1build1) ...\n",
            "Selecting previously unselected package xserver-xorg-dev.\n",
            "Preparing to unpack .../88-xserver-xorg-dev_2%3a1.20.13-1ubuntu1~20.04.8_amd64.deb ...\n",
            "Unpacking xserver-xorg-dev (2:1.20.13-1ubuntu1~20.04.8) ...\n",
            "Selecting previously unselected package libosmesa6:amd64.\n",
            "Preparing to unpack .../89-libosmesa6_21.2.6-0ubuntu0.1~20.04.2_amd64.deb ...\n",
            "Unpacking libosmesa6:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\n",
            "Selecting previously unselected package libosmesa6-dev:amd64.\n",
            "Preparing to unpack .../90-libosmesa6-dev_21.2.6-0ubuntu0.1~20.04.2_amd64.deb ...\n",
            "Unpacking libosmesa6-dev:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\n",
            "Selecting previously unselected package libwayland-bin.\n",
            "Preparing to unpack .../91-libwayland-bin_1.18.0-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libwayland-bin (1.18.0-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libwayland-dev:amd64.\n",
            "Preparing to unpack .../92-libwayland-dev_1.18.0-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libwayland-dev:amd64 (1.18.0-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python3-setproctitle:amd64.\n",
            "Preparing to unpack .../93-python3-setproctitle_1.1.10-1ubuntu1_amd64.deb ...\n",
            "Unpacking python3-setproctitle:amd64 (1.1.10-1ubuntu1) ...\n",
            "Setting up python3-more-itertools (4.2.0-1build1) ...\n",
            "Setting up javascript-common (11) ...\n",
            "Setting up libglfw3:amd64 (3.3.2-1) ...\n",
            "Setting up net-tools (1.60+git20180626.aebd88e-1ubuntu1) ...\n",
            "Setting up python3-filelock (3.0.12-2) ...\n",
            "Setting up gir1.2-freedesktop:amd64 (1.64.1-1~ubuntu20.04.1) ...\n",
            "Setting up libpixman-1-dev:amd64 (0.38.4-0ubuntu2.1) ...\n",
            "Setting up libpciaccess-dev:amd64 (0.16-0ubuntu1) ...\n",
            "Setting up python3-cairo:amd64 (1.16.2-2ubuntu2) ...\n",
            "Setting up python3-rencode (1.0.6-1build1) ...\n",
            "Setting up libpangoxft-1.0-0:amd64 (1.44.7-2ubuntu4) ...\n",
            "Setting up libglfw3-dev:amd64 (3.3.2-1) ...\n",
            "Setting up gir1.2-gdkpixbuf-2.0:amd64 (2.40.0+dfsg-3ubuntu0.4) ...\n",
            "Setting up python3-lz4 (3.0.2+dfsg-1build1) ...\n",
            "Setting up gir1.2-atk-1.0:amd64 (2.35.1-1ubuntu2) ...\n",
            "Setting up x11proto-randr-dev (2019.2-1ubuntu1) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1) ...\n",
            "Setting up python3-olefile (0.46-2) ...\n",
            "Setting up libdbusmenu-glib4:amd64 (16.04.1+18.10.20180917-0ubuntu6) ...\n",
            "Setting up python3-kerberos (1.1.14-3.1build1) ...\n",
            "Setting up liblzo2-2:amd64 (2.10-2) ...\n",
            "Setting up python3-distlib (0.3.0-1) ...\n",
            "Setting up python3-zipp (1.0.0-1) ...\n",
            "Setting up python3-opengl (3.1.0+dfsg-2build1) ...\n",
            "Setting up python3-xdg (0.26-1ubuntu1) ...\n",
            "Setting up x11-xserver-utils (7.7+8) ...\n",
            "Setting up python3-nose (1.3.7-5) ...\n",
            "Setting up python3-ifaddr (0.1.6-1) ...\n",
            "Setting up libwayland-bin (1.18.0-1ubuntu0.1) ...\n",
            "Setting up python3-decorator (4.4.2-0ubuntu1) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-0ubuntu1) ...\n",
            "Setting up gir1.2-pango-1.0:amd64 (1.44.7-2ubuntu4) ...\n",
            "Setting up libxrandr-dev:amd64 (2:1.5.2-0ubuntu1) ...\n",
            "Setting up ssh-askpass (1:1.2.4.1-10) ...\n",
            "update-alternatives: using /usr/lib/ssh/x11-ssh-askpass to provide /usr/bin/ssh-askpass (ssh-askpass) in auto mode\n",
            "Setting up python3-gssapi (1.6.1-1build1) ...\n",
            "Setting up python3-brotli (1.0.7-6ubuntu0.1) ...\n",
            "Setting up libgles1:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu1) ...\n",
            "Setting up libimagequant0:amd64 (2.12.2-1.1) ...\n",
            "Setting up python3-setproctitle:amd64 (1.1.10-1ubuntu1) ...\n",
            "Setting up udev (245.4-4ubuntu3.21) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up python3-dns (3.2.1-1) ...\n",
            "Setting up python3-cpuinfo (5.0.0-2) ...\n",
            "Setting up python3-numpy (1:1.17.4-5ubuntu3.1) ...\n",
            "Setting up libgl1-mesa-glx:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\n",
            "Setting up libglew2.1:amd64 (2.1.0-4) ...\n",
            "Setting up python-pip-whl (20.0.2-5ubuntu1.8) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1) ...\n",
            "Setting up libopengl-dev:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\n",
            "Setting up libjs-jquery (3.3.1~dfsg-3) ...\n",
            "Setting up libgles-dev:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\n",
            "Setting up patchelf (0.10-2build1) ...\n",
            "Setting up python3-gi-cairo (3.36.0-1) ...\n",
            "Setting up python3-appdirs (1.4.3-2.1) ...\n",
            "Setting up libxfont2:amd64 (1:2.0.3-1) ...\n",
            "Setting up liblocale-gettext-perl (1.07-4) ...\n",
            "Setting up python3-lzo (1.12-3build2) ...\n",
            "Setting up python3-cffi-backend (1.14.0-1build1) ...\n",
            "Setting up libjs-underscore (1.9.1~dfsg-1ubuntu0.20.04.1) ...\n",
            "Setting up libxkbfile-dev:amd64 (1:1.1.0-1) ...\n",
            "Setting up libosmesa6:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\n",
            "Setting up libdrm-dev:amd64 (2.4.107-8ubuntu1~20.04.2) ...\n",
            "Setting up libdbusmenu-gtk3-4:amd64 (16.04.1+18.10.20180917-0ubuntu6) ...\n",
            "Setting up python3-importlib-metadata (1.5.0-1) ...\n",
            "Setting up python3-zeroconf (0.24.4-0ubuntu1) ...\n",
            "Setting up x11-xkb-utils (7.7+5) ...\n",
            "Setting up python3-bcrypt (3.1.7-2ubuntu1) ...\n",
            "Setting up gir1.2-gtk-3.0:amd64 (3.24.20-0ubuntu1.1) ...\n",
            "Setting up libfontenc-dev:amd64 (1:1.1.4-0ubuntu1) ...\n",
            "Setting up python3-virtualenv (20.0.17-1ubuntu0.4) ...\n",
            "Setting up libglvnd-dev:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\n",
            "Setting up xfonts-utils (1:7.7+6) ...\n",
            "Setting up libwayland-dev:amd64 (1.18.0-1ubuntu0.1) ...\n",
            "Setting up libappindicator3-1 (12.10.1+20.04.20200408.1-0ubuntu1) ...\n",
            "Setting up python3-pil:amd64 (7.0.0-4ubuntu0.7) ...\n",
            "Setting up libglew-dev:amd64 (2.1.0-4) ...\n",
            "Setting up xfonts-base (1:1.0.5) ...\n",
            "Setting up gir1.2-appindicator3-0.1 (12.10.1+20.04.20200408.1-0ubuntu1) ...\n",
            "Setting up python3-cryptography (2.8-3ubuntu0.1) ...\n",
            "Setting up virtualenv (20.0.17-1ubuntu0.4) ...\n",
            "Setting up libjs-sphinxdoc (1.8.5-7ubuntu3) ...\n",
            "Setting up libosmesa6-dev:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\n",
            "Setting up libgl1-mesa-dev:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\n",
            "Setting up mesa-common-dev:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\n",
            "Setting up xserver-common (2:1.20.13-1ubuntu1~20.04.8) ...\n",
            "Setting up keyboard-configuration (1.194ubuntu3) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Configuring keyboard-configuration\n",
            "----------------------------------\n",
            "\n",
            "The layout of keyboards varies per country, with some countries having multiple\n",
            "common layouts. Please select the country of origin for the keyboard of this\n",
            "computer.\n",
            "\n",
            "  1. Afghani\n",
            "  2. Albanian\n",
            "  3. Amharic\n",
            "  4. Arabic\n",
            "  5. Arabic (Morocco)\n",
            "  6. Arabic (Syria)\n",
            "  7. Armenian\n",
            "  8. Azerbaijani\n",
            "  9. Bambara\n",
            "  10. Bangla\n",
            "  11. Belarusian\n",
            "  12. Belgian\n",
            "  13. Berber (Algeria, Latin)\n",
            "  14. Bosnian\n",
            "  15. Braille\n",
            "  16. Bulgarian\n",
            "  17. Burmese\n",
            "  18. Chinese\n",
            "  19. Croatian\n",
            "  20. Czech\n",
            "  21. Danish\n",
            "  22. Dhivehi\n",
            "  23. Dutch\n",
            "  24. Dzongkha\n",
            "  25. English (Australian)\n",
            "  26. English (Cameroon)\n",
            "  27. English (Ghana)\n",
            "  28. English (Nigeria)\n",
            "  29. English (South Africa)\n",
            "  30. English (UK)\n",
            "  31. English (US)\n",
            "  32. Esperanto\n",
            "  33. Estonian\n",
            "  34. Faroese\n",
            "  35. Filipino\n",
            "  36. Finnish\n",
            "  37. French\n",
            "  38. French (Canada)\n",
            "  39. French (Democratic Republic of the Congo)\n",
            "  40. French (Guinea)\n",
            "  41. French (Togo)\n",
            "  42. Georgian\n",
            "  43. German\n",
            "  44. German (Austria)\n",
            "  45. Greek\n",
            "  46. Hebrew\n",
            "  47. Hungarian\n",
            "  48. Icelandic\n",
            "  49. Indian\n",
            "  50. Indonesian (Arab Melayu, phonetic)\n",
            "  51. Indonesian (Javanese)\n",
            "  52. Iraqi\n",
            "  53. Irish\n",
            "  54. Italian\n",
            "  55. Japanese\n",
            "  56. Japanese (PC-98)\n",
            "  57. Kazakh\n",
            "  58. Khmer (Cambodia)\n",
            "  59. Korean\n",
            "  60. Kyrgyz\n",
            "  61. Lao\n",
            "  62. Latvian\n",
            "  63. Lithuanian\n",
            "  64. Macedonian\n",
            "  65. Malay (Jawi, Arabic Keyboard)\n",
            "  66. Maltese\n",
            "  67. Maori\n",
            "  68. Moldavian\n",
            "  69. Mongolian\n",
            "  70. Montenegrin\n",
            "  71. Nepali\n",
            "  72. Norwegian\n",
            "  73. Persian\n",
            "  74. Polish\n",
            "  75. Portuguese\n",
            "  76. Portuguese (Brazil)\n",
            "  77. Romanian\n",
            "  78. Russian\n",
            "  79. Serbian\n",
            "  80. Sinhala (phonetic)\n",
            "  81. Slovak\n",
            "  82. Slovenian\n",
            "  83. Spanish\n",
            "  84. Spanish (Latin American)\n",
            "  85. Swahili (Kenya)\n",
            "  86. Swahili (Tanzania)\n",
            "  87. Swedish\n",
            "  88. Switzerland\n",
            "  89. Taiwanese\n",
            "  90. Tajik\n",
            "  91. Thai\n",
            "  92. Tswana\n",
            "  93. Turkish\n",
            "  94. Turkmen\n",
            "  95. Ukrainian\n",
            "  96. Urdu (Pakistan)\n",
            "  97. Uzbek\n",
            "  98. Vietnamese\n",
            "  99. Wolof\n",
            "\u001b[4mCountry of origin for the keyboard: \u001b[m\u001b[1m31\n",
            "\u001b[m\u001b[m\n",
            "Please select the layout matching the keyboard for this machine.\n",
            "\n",
            "  1. English (US)\n",
            "  2. English (US) - Cherokee\n",
            "  3. English (US) - English (classic Dvorak)\n",
            "  4. English (US) - English (Colemak)\n",
            "  5. English (US) - English (Dvorak)\n",
            "  6. English (US) - English (Dvorak, alt. intl.)\n",
            "  7. English (US) - English (Dvorak, intl., with dead keys)\n",
            "  8. English (US) - English (Dvorak, left-handed)\n",
            "  9. English (US) - English (Dvorak, right-handed)\n",
            "  10. English (US) - English (intl., with AltGr dead keys)\n",
            "  11. English (US) - English (Macintosh)\n",
            "  12. English (US) - English (Norman)\n",
            "  13. English (US) - English (programmer Dvorak)\n",
            "  14. English (US) - English (the divide/multiply keys toggle the layout)\n",
            "  15. English (US) - English (US, alt. intl.)\n",
            "  16. English (US) - English (US, euro on 5)\n",
            "  17. English (US) - English (US, intl., with dead keys)\n",
            "  18. English (US) - English (Workman)\n",
            "  19. English (US) - English (Workman, intl., with dead keys)\n",
            "  20. English (US) - Russian (US, phonetic)\n",
            "  21. English (US) - Serbo-Croatian (US)\n",
            "\u001b[4mKeyboard layout: \u001b[m\u001b[1m1\n",
            "\u001b[m\u001b[m\n",
            "Your console font configuration will be updated the next time your system\n",
            "boots. If you want to update it now, run 'setupcon' from a virtual console.\n",
            "Setting up python3-nacl (1.3.0-5) ...\n",
            "Setting up libegl1-mesa-dev:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\n",
            "Setting up python3-uritools (3.0.0-1) ...\n",
            "Setting up libxfont-dev (1:2.0.3-1) ...\n",
            "Setting up xserver-xorg-core (2:1.20.13-1ubuntu1~20.04.8) ...\n",
            "Setting up xserver-xorg-video-dummy (1:0.3.8-1build3) ...\n",
            "Setting up xserver-xorg-input-void (1:1.4.1-1build3) ...\n",
            "Setting up python3-paramiko (2.6.0-2ubuntu0.1) ...\n",
            "Setting up xserver-xorg-dev (2:1.20.13-1ubuntu1~20.04.8) ...\n",
            "Setting up xpra (3.0.6+dfsg1-1build1) ...\n",
            "Processing triggers for dbus (1.12.16-2ubuntu2.3) ...\n",
            "Processing triggers for shared-mime-info (1.15-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-2ubuntu3) ...\n",
            "Processing triggers for mime-support (3.64ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n",
            "Processing triggers for systemd (245.4-4ubuntu3.21) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n"
          ]
        }
      ],
      "source": [
        "###### libs for install ######\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install gcc\n",
        "\n",
        "!sudo apt-get build-dep mesa\n",
        "!sudo apt-get install llvm-dev\n",
        "!sudo apt-get install freeglut3 freeglut3-dev\n",
        "\n",
        "!sudo apt-get install python3-dev\n",
        "\n",
        "!sudo apt-get install build-essential\n",
        "\n",
        "!sudo apt install curl git libgl1-mesa-dev libgl1-mesa-glx libglew-dev \\\n",
        "        libosmesa6-dev software-properties-common net-tools unzip vim \\\n",
        "        virtualenv wget xpra xserver-xorg-dev libglfw3-dev patchelf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23eqLoV_orip",
        "outputId": "cfa672e9-0fc2-4751-e3a7-85234b76aa5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-07 22:42:06--  https://roboti.us/download/mujoco200_linux.zip\n",
            "Resolving roboti.us (roboti.us)... 104.40.85.93\n",
            "Connecting to roboti.us (roboti.us)|104.40.85.93|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4427362 (4.2M) [application/zip]\n",
            "Saving to: ‘mujoco200_linux.zip’\n",
            "\n",
            "mujoco200_linux.zip 100%[===================>]   4.22M  5.52MB/s    in 0.8s    \n",
            "\n",
            "2023-05-07 22:42:07 (5.52 MB/s) - ‘mujoco200_linux.zip’ saved [4427362/4427362]\n",
            "\n",
            "--2023-05-07 22:42:07--  https://roboti.us/file/mjkey.txt\n",
            "Resolving roboti.us (roboti.us)... 104.40.85.93\n",
            "Connecting to roboti.us (roboti.us)|104.40.85.93|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 768 [text/plain]\n",
            "Saving to: ‘mjkey.txt’\n",
            "\n",
            "mjkey.txt           100%[===================>]     768  --.-KB/s    in 0s      \n",
            "\n",
            "2023-05-07 22:42:07 (56.1 MB/s) - ‘mjkey.txt’ saved [768/768]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "###### mujoco setup ######\n",
        "!wget https://roboti.us/download/mujoco200_linux.zip\n",
        "!wget https://roboti.us/file/mjkey.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcXVniz_p4RN",
        "outputId": "8e834050-c8f4-4c6f-ef4d-fe12e2afd5d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  mujoco200_linux.zip\n",
            "   creating: /root/.mujoco/mujoco200_linux/\n",
            "   creating: /root/.mujoco/mujoco200_linux/sample/\n",
            "  inflating: /root/.mujoco/mujoco200_linux/sample/mjxmake.m  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/sample/makefile  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/sample/mjx.cpp  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/sample/simulate.cpp  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/sample/record.cpp  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/sample/basic.cpp  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/sample/derivative.cpp  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/sample/compile.cpp  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/sample/testspeed.cpp  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/sample/testxml.cpp  \n",
            "   creating: /root/.mujoco/mujoco200_linux/model/\n",
            "  inflating: /root/.mujoco/mujoco200_linux/model/sponge.png  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/model/softellipsoid.xml  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/model/softcylinder.xml  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/model/softbox.xml  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/model/scene.xml  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/model/rope.xml  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/model/particle.xml  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/model/marble.png  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/model/loop.xml  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/model/grid2pin.xml  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/model/grid2.xml  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/model/grid1pin.xml  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/model/grid1.xml  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/model/cloth.xml  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/model/carpet.png  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/model/hammock.xml  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/model/humanoid100.xml  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/model/humanoid.xml  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/model/arm26.xml  \n",
            "   creating: /root/.mujoco/mujoco200_linux/include/\n",
            "  inflating: /root/.mujoco/mujoco200_linux/include/uitools.h  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/include/uitools.c  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/include/mujoco.h  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/include/mjxmacro.h  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/include/mjvisualize.h  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/include/mjui.h  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/include/mjrender.h  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/include/mjmodel.h  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/include/mjdata.h  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/include/glfw3.h  \n",
            "   creating: /root/.mujoco/mujoco200_linux/doc/\n",
            "  inflating: /root/.mujoco/mujoco200_linux/doc/README.txt  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/doc/REFERENCE.txt  \n",
            "   creating: /root/.mujoco/mujoco200_linux/bin/\n",
            "  inflating: /root/.mujoco/mujoco200_linux/bin/libmujoco200.so  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/bin/simulate  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/bin/record  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/bin/basic  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/bin/derivative  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/bin/compile  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/bin/testspeed  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/bin/testxml  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/bin/libmujoco200nogl.so  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/bin/libglfw3.a  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/bin/libglfw.so.3  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/bin/libglewosmesa.so  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/bin/libglewegl.so  \n",
            "  inflating: /root/.mujoco/mujoco200_linux/bin/libglew.so  \n"
          ]
        }
      ],
      "source": [
        "!mkdir /root/.mujoco\n",
        "\n",
        "### mujoco 200\n",
        "!unzip mujoco200_linux.zip -d /root/.mujoco/\n",
        "!cp -r /root/.mujoco/mujoco200_linux /root/.mujoco/mujoco200\n",
        "\n",
        "!mv mjkey.txt /root/.mujoco/\n",
        "\n",
        "!cp -r /root/.mujoco/mujoco200/bin/* /usr/lib/ # need to do this again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-X3JOM3RTcPO",
        "outputId": "114ceced-a6aa-4ac3-b2f5-185842e676af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 24K\n",
            "drwxr-xr-x 4 root root 4.0K May  7 22:42 .\n",
            "drwx------ 1 root root 4.0K May  7 22:42 ..\n",
            "-rw-r--r-- 1 root root  768 Oct 18  2021 mjkey.txt\n",
            "drwxr-xr-x 7 root root 4.0K May  7 22:42 mujoco200\n",
            "drwxrwxr-x 7 root root 4.0K Oct  2  2018 mujoco200_linux\n"
          ]
        }
      ],
      "source": [
        "!ls -alh /root/.mujoco/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVQWcww_uZMo",
        "outputId": "401d9372-9cfd-4bfe-fdf2-91c1967cba35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/root/.mujoco/mujoco200/bin\n"
          ]
        }
      ],
      "source": [
        "%env LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/root/.mujoco/mujoco200/bin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AviuDDxpqhOs",
        "outputId": "be331dab-c586-441e-fe35-e9304ac59c7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mujoco_py==2.0.2.8\n",
            "  Downloading mujoco_py-2.0.2.8-py3-none-any.whl (4.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: imageio>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from mujoco_py==2.0.2.8) (2.25.1)\n",
            "Requirement already satisfied: cffi>=1.10 in /usr/local/lib/python3.10/dist-packages (from mujoco_py==2.0.2.8) (1.15.1)\n",
            "Requirement already satisfied: Cython>=0.27.2 in /usr/local/lib/python3.10/dist-packages (from mujoco_py==2.0.2.8) (0.29.34)\n",
            "Collecting fasteners~=0.15\n",
            "  Downloading fasteners-0.18-py3-none-any.whl (18 kB)\n",
            "Collecting glfw>=1.4.0\n",
            "  Downloading glfw-2.5.9-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.8/207.8 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.10/dist-packages (from mujoco_py==2.0.2.8) (1.22.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.10->mujoco_py==2.0.2.8) (2.21)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio>=2.1.2->mujoco_py==2.0.2.8) (8.4.0)\n",
            "Installing collected packages: glfw, fasteners, mujoco_py\n",
            "Successfully installed fasteners-0.18 glfw-2.5.9 mujoco_py-2.0.2.8\n"
          ]
        }
      ],
      "source": [
        "###### mujoco-py setup ######\n",
        "!pip install mujoco_py==2.0.2.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duUbqfKEordx",
        "outputId": "8ad5c4a7-fa7c-4ae5-9cc8-a68ce663abb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'd4rl'...\n",
            "remote: Enumerating objects: 1373, done.\u001b[K\n",
            "remote: Counting objects: 100% (617/617), done.\u001b[K\n",
            "remote: Compressing objects: 100% (314/314), done.\u001b[K\n",
            "remote: Total 1373 (delta 335), reused 406 (delta 300), pack-reused 756\u001b[K\n",
            "Receiving objects: 100% (1373/1373), 28.57 MiB | 28.86 MiB/s, done.\n",
            "Resolving deltas: 100% (673/673), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/d4rl\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mjrl@ git+https://github.com/aravindr93/mjrl@master#egg=mjrl\n",
            "  Cloning https://github.com/aravindr93/mjrl (to revision master) to /tmp/pip-install-afyr5lob/mjrl_87509340f84d4610b27857144f0e59b9\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/aravindr93/mjrl /tmp/pip-install-afyr5lob/mjrl_87509340f84d4610b27857144f0e59b9\n",
            "  Resolved https://github.com/aravindr93/mjrl to commit 3871d93763d3b49c4741e6daeaebbc605fe140dc\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gym<0.24.0\n",
            "  Downloading gym-0.23.1.tar.gz (626 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m626.2/626.2 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from D4RL==1.1) (1.22.4)\n",
            "Requirement already satisfied: mujoco_py in /usr/local/lib/python3.10/dist-packages (from D4RL==1.1) (2.0.2.8)\n",
            "Collecting pybullet\n",
            "  Downloading pybullet-3.2.5.tar.gz (80.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.5/80.5 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from D4RL==1.1) (3.8.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from D4RL==1.1) (2.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from D4RL==1.1) (8.1.3)\n",
            "Collecting dm_control>=1.0.3\n",
            "  Downloading dm_control-1.0.12-py3-none-any.whl (39.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from dm_control>=1.0.3->D4RL==1.1) (2.27.1)\n",
            "Requirement already satisfied: pyparsing>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from dm_control>=1.0.3->D4RL==1.1) (3.0.9)\n",
            "Requirement already satisfied: pyopengl>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from dm_control>=1.0.3->D4RL==1.1) (3.1.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from dm_control>=1.0.3->D4RL==1.1) (1.10.1)\n",
            "Collecting labmaze\n",
            "  Downloading labmaze-1.0.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from dm_control>=1.0.3->D4RL==1.1) (4.9.2)\n",
            "Requirement already satisfied: protobuf>=3.19.4 in /usr/local/lib/python3.10/dist-packages (from dm_control>=1.0.3->D4RL==1.1) (3.20.3)\n",
            "Collecting dm-env\n",
            "  Downloading dm_env-1.6-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from dm_control>=1.0.3->D4RL==1.1) (1.4.0)\n",
            "Collecting mujoco>=2.3.4\n",
            "  Downloading mujoco-2.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dm_control>=1.0.3->D4RL==1.1) (4.65.0)\n",
            "Requirement already satisfied: setuptools!=50.0.0 in /usr/local/lib/python3.10/dist-packages (from dm_control>=1.0.3->D4RL==1.1) (67.7.2)\n",
            "Requirement already satisfied: glfw in /usr/local/lib/python3.10/dist-packages (from dm_control>=1.0.3->D4RL==1.1) (2.5.9)\n",
            "Requirement already satisfied: dm-tree!=0.1.2 in /usr/local/lib/python3.10/dist-packages (from dm_control>=1.0.3->D4RL==1.1) (0.1.8)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym<0.24.0->D4RL==1.1) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym<0.24.0->D4RL==1.1) (0.0.8)\n",
            "Requirement already satisfied: imageio>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from mujoco_py->D4RL==1.1) (2.25.1)\n",
            "Requirement already satisfied: cffi>=1.10 in /usr/local/lib/python3.10/dist-packages (from mujoco_py->D4RL==1.1) (1.15.1)\n",
            "Requirement already satisfied: fasteners~=0.15 in /usr/local/lib/python3.10/dist-packages (from mujoco_py->D4RL==1.1) (0.18)\n",
            "Requirement already satisfied: Cython>=0.27.2 in /usr/local/lib/python3.10/dist-packages (from mujoco_py->D4RL==1.1) (0.29.34)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.10->mujoco_py->D4RL==1.1) (2.21)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio>=2.1.2->mujoco_py->D4RL==1.1) (8.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->dm_control>=1.0.3->D4RL==1.1) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->dm_control>=1.0.3->D4RL==1.1) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->dm_control>=1.0.3->D4RL==1.1) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->dm_control>=1.0.3->D4RL==1.1) (3.4)\n",
            "Building wheels for collected packages: gym, mjrl, pybullet\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.23.1-py3-none-any.whl size=701375 sha256=96400c1e5b50622e7eb7637eca17746e0fc31066a96230c6ea09f0202cfbc39d\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/00/fb/fe5cf2860fb9b7bc860e28f00095a1f42c7b726dd6f42d1acc\n",
            "  Building wheel for mjrl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mjrl: filename=mjrl-1.0.0-py3-none-any.whl size=61954 sha256=759e64281042ec40128368491307d4277b182474d8f59dd0c66bebc5e5e9f3bd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-kvkvrpmt/wheels/8f/99/f9/efd223b38d503df5eaada10ffe96a869fb0c0f3c92d9e43ed0\n",
            "  Building wheel for pybullet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pybullet: filename=pybullet-3.2.5-cp310-cp310-linux_x86_64.whl size=101451682 sha256=4dc154c3c050061790af489d1e6e613d12c510c14c0831cf8d6e8721b552044e\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/fa/1a/c315a5133f0c9bf202a6daa5d70891120e7fe403e06e3407cc\n",
            "Successfully built gym mjrl pybullet\n",
            "Installing collected packages: pybullet, mjrl, mujoco, labmaze, gym, dm-env, dm_control, D4RL\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "  Running setup.py develop for D4RL\n",
            "Successfully installed D4RL-1.1 dm-env-1.6 dm_control-1.0.12 gym-0.23.1 labmaze-1.0.6 mjrl-1.0.0 mujoco-2.3.5 pybullet-3.2.5\n"
          ]
        }
      ],
      "source": [
        "###### D4RL setup ######\n",
        "!git clone https://github.com/rail-berkeley/d4rl.git\n",
        "### edit dm_control version in d4rl setup.py\n",
        "!sed -i \"s;dm_control @ git+git://github.com/deepmind/dm_control@master#egg=dm_control;dm_control==0.0.364896371;g\" /content/d4rl/setup.py\n",
        "### edit mjrl install in d4rl setup.py to use github's new https protocol instead of git SSH\n",
        "!sed -i \"s;mjrl @ git+git://github.com/aravindr93/mjrl@master#egg=mjrl;mjrl @ git+https://github.com/aravindr93/mjrl@master#egg=mjrl;g\" /content/d4rl/setup.py\n",
        "!pip install -e d4rl/."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVrmCbNMAwQk"
      },
      "outputs": [],
      "source": [
        "###### restart runtime ######\n",
        "exit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBD3fRknjEj6"
      },
      "source": [
        "# check mujoco-py and D4RL installation\n",
        "\n",
        "* if check fails then **Restart Runtime** again\n",
        "* if check still fails then Factory reset runtime and install again\n",
        "* After installing, first import will be slow as the lib will be built again\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uycTGiqjKYK",
        "outputId": "10b4bcf7-dbdc-4947-e99b-7118a3f8f764"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/root/.mujoco/mujoco200/bin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/mujoco_py/builder.py:9: DeprecationWarning: The distutils.sysconfig module is deprecated, use sysconfig instead\n",
            "  from distutils.sysconfig import customize_compiler\n",
            "<frozen importlib._bootstrap>:283: DeprecationWarning: the load_module() method is deprecated and slated for removal in Python 3.12; use exec_module() instead\n",
            "Warning: Flow failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\n",
            "No module named 'flow'\n",
            "/usr/local/lib/python3.10/dist-packages/glfw/__init__.py:916: GLFWError: (65544) b'X11: The DISPLAY environment variable is missing'\n",
            "  warnings.warn(message, GLFWError)\n",
            "Warning: CARLA failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\n",
            "No module named 'carla'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mujoco-py check passed\n"
          ]
        }
      ],
      "source": [
        "# set mujoco env path if not already set\n",
        "%env LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/root/.mujoco/mujoco200/bin\n",
        "\n",
        "import gym\n",
        "import d4rl # Import required to register environments\n",
        "\n",
        "env = gym.make('HalfCheetah-v3')\n",
        "env.reset()\n",
        "env.step(env.action_space.sample())\n",
        "env.close()\n",
        "print(\"mujoco-py check passed\")\n",
        "\n",
        "# env = gym.make('maze2d-open-dense-medium-v2')\n",
        "# env.reset()\n",
        "# env.step(env.action_space.sample())\n",
        "# env.close()\n",
        "# print(\"d4rl check passed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TpGEYTblzQc"
      },
      "source": [
        "# download D4RL data\n",
        "\n",
        "*   skip this block if data is already downloaded\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V31ELEKOih7D",
        "outputId": "760bd6ad-0f17-418e-81b9-ff66d4c6a8fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/root/.mujoco/mujoco200/bin\n",
            "./data\n",
            "processing:  halfcheetah-medium-v2\n",
            "Downloading dataset: http://rail.eecs.berkeley.edu/datasets/offline_rl/gym_mujoco_v2/halfcheetah_medium-v2.hdf5 to /root/.d4rl/datasets/halfcheetah_medium-v2.hdf5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/gym/spaces/box.py:84: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
            "load datafile: 100%|██████████| 21/21 [00:03<00:00,  5.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples collected: 1000000\n",
            "Trajectory returns: mean = 4770.3349609375, std = 355.7503967285156, max = 5309.37939453125, min = -310.23419189453125\n",
            "processing:  halfcheetah-medium-expert-v2\n",
            "Downloading dataset: http://rail.eecs.berkeley.edu/datasets/offline_rl/gym_mujoco_v2/halfcheetah_medium_expert-v2.hdf5 to /root/.d4rl/datasets/halfcheetah_medium_expert-v2.hdf5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "load datafile: 100%|██████████| 9/9 [00:04<00:00,  1.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples collected: 2000000\n",
            "Trajectory returns: mean = 7713.38037109375, std = 2970.242431640625, max = 11252.03515625, min = -310.23419189453125\n",
            "processing:  halfcheetah-medium-replay-v2\n",
            "Downloading dataset: http://rail.eecs.berkeley.edu/datasets/offline_rl/gym_mujoco_v2/halfcheetah_medium_replay-v2.hdf5 to /root/.d4rl/datasets/halfcheetah_medium_replay-v2.hdf5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "load datafile: 100%|██████████| 11/11 [00:00<00:00, 19.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples collected: 202000\n",
            "Trajectory returns: mean = 3093.28564453125, std = 1680.6939697265625, max = 4985.1416015625, min = -638.4852905273438\n"
          ]
        }
      ],
      "source": [
        "# set mujoco env path if not already set\n",
        "%env LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/root/.mujoco/mujoco200/bin\n",
        "\n",
        "import os\n",
        "import gym\n",
        "import numpy as np\n",
        "\n",
        "import collections\n",
        "import pickle\n",
        "\n",
        "import d4rl\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "datasets = []\n",
        "\n",
        "data_dir = \"./data\"\n",
        "\n",
        "print(data_dir)\n",
        "\n",
        "if not os.path.exists(data_dir):\n",
        "    os.makedirs(data_dir)\n",
        "\n",
        "for env_name in ['halfcheetah']:\n",
        "    for dataset_type in ['medium', 'medium-expert', 'medium-replay']:\n",
        "\t\t\n",
        "        name = f'{env_name}-{dataset_type}-v2'\n",
        "        pkl_file_path = os.path.join(data_dir, name)\n",
        "\n",
        "        print(\"processing: \", name)\n",
        "\n",
        "        env = gym.make(name)\n",
        "        dataset = env.get_dataset()\n",
        "\n",
        "        N = dataset['rewards'].shape[0]\n",
        "        data_ = collections.defaultdict(list)\n",
        "\n",
        "        use_timeouts = False\n",
        "        if 'timeouts' in dataset:\n",
        "            use_timeouts = True\n",
        "\n",
        "        episode_step = 0\n",
        "        paths = []\n",
        "        for i in range(N):\n",
        "            done_bool = bool(dataset['terminals'][i])\n",
        "            if use_timeouts:\n",
        "                final_timestep = dataset['timeouts'][i]\n",
        "            else:\n",
        "                final_timestep = (episode_step == 1000-1)\n",
        "            for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:\n",
        "                data_[k].append(dataset[k][i])\n",
        "            if done_bool or final_timestep:\n",
        "                episode_step = 0\n",
        "                episode_data = {}\n",
        "                for k in data_:\n",
        "                    episode_data[k] = np.array(data_[k])\n",
        "                paths.append(episode_data)\n",
        "                data_ = collections.defaultdict(list)\n",
        "            episode_step += 1\n",
        "\n",
        "        returns = np.array([np.sum(p['rewards']) for p in paths])\n",
        "        num_samples = np.sum([p['rewards'].shape[0] for p in paths])\n",
        "        print(f'Number of samples collected: {num_samples}')\n",
        "        print(f'Trajectory returns: mean = {np.mean(returns)}, std = {np.std(returns)}, max = {np.max(returns)}, min = {np.min(returns)}')\n",
        "\n",
        "        with open(f'{pkl_file_path}.pkl', 'wb') as f:\n",
        "            pickle.dump(paths, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2Nk5Gp7hUGA"
      },
      "source": [
        "# import libs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4xiijmBixUm",
        "outputId": "4f31e745-abd7-4dd7-bfc5-96cddfc5edef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/root/.mujoco/mujoco200/bin\n"
          ]
        }
      ],
      "source": [
        "# set mujoco env path if not already set\n",
        "%env LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/root/.mujoco/mujoco200/bin\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import csv\n",
        "from datetime import datetime\n",
        "import pickle\n",
        "import collections\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import gym\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQcLNRgD6SaW"
      },
      "source": [
        "# training parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdtDsvit6m_e",
        "outputId": "e7dfa0f1-a5b6-4d5a-93bd-94da8ef4fb20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device set to:  cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "dataset = \"\"       # medium / medium-replay / medium-expert\n",
        "rtg_scale = 1000         # scale to normalize returns to go\n",
        "\n",
        "# use v3 env for evaluation because\n",
        "# DT paper evaluates results on v3 envs\n",
        "\n",
        "# env_name = 'maze2d-open-dense-v0'\n",
        "# rtg_target = 5000\n",
        "# env_d4rl_name = f'maze2d-open-dense-v0'\n",
        "\n",
        "# env_name = 'HalfCheetah-v3'\n",
        "# rtg_target = 6000\n",
        "# env_d4rl_name = f'halfcheetah-{dataset}-v2'\n",
        "\n",
        "# env_name = 'Hopper-v3'\n",
        "# rtg_target = 3600\n",
        "# env_d4rl_name = f'hopper-{dataset}-v2'\n",
        "\n",
        "env_name = 'HalfCheetah-v3'\n",
        "rtg_target = 6000\n",
        "env_d4rl_name = f'halfcheetah-medium-expert-v2'\n",
        "\n",
        "max_eval_ep_len = 1000      # max len of one evaluation episode\n",
        "num_eval_ep = 10            # num of evaluation episodes per iteration\n",
        "\n",
        "batch_size = 64             # training batch size\n",
        "lr = 1e-4                   # learning rate\n",
        "wt_decay = 1e-4             # weight decay\n",
        "warmup_steps = 10000        # warmup steps for lr scheduler\n",
        "\n",
        "# total updates = max_train_iters x num_updates_per_iter\n",
        "# max_train_iters = 200\n",
        "max_train_iters = 200\n",
        "num_updates_per_iter = 100\n",
        "\n",
        "context_len = 20        # K in decision transformer\n",
        "n_blocks = 3            # num of transformer blocks\n",
        "embed_dim = 128         # embedding (hidden) dim of transformer\n",
        "n_heads = 1             # num of transformer heads\n",
        "dropout_p = 0.1         # dropout probability\n",
        "\n",
        "# load data from this file\n",
        "dataset_path = f'data/{env_d4rl_name}.pkl'\n",
        "\n",
        "# saves model and csv in this directory\n",
        "log_dir = \"./dt_runs/\"\n",
        "\n",
        "if not os.path.exists(log_dir):\n",
        "    os.makedirs(log_dir)\n",
        "\n",
        "# training and evaluation device\n",
        "device_name = 'cuda'\n",
        "device = torch.device(device_name)\n",
        "print(\"device set to: \", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNJM0LG1iziA"
      },
      "source": [
        "# decision transformer model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHMl_Y1SicXb"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "this extremely minimal GPT model is based on:\n",
        "Misha Laskin's tweet: \n",
        "https://twitter.com/MishaLaskin/status/1481767788775628801?cxt=HHwWgoCzmYD9pZApAAAA\n",
        "\n",
        "and its corresponding notebook:\n",
        "https://colab.research.google.com/drive/1NUBqyboDcGte5qAJKOl8gaJC28V_73Iv?usp=sharing\n",
        "\n",
        "the above colab has a bug while applying masked_fill which is fixed in the\n",
        "following code\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "class MaskedCausalAttention(nn.Module):\n",
        "    def __init__(self, h_dim, max_T, n_heads, drop_p):\n",
        "        super().__init__()\n",
        "\n",
        "        self.n_heads = n_heads\n",
        "        self.max_T = max_T\n",
        "\n",
        "        self.q_net = nn.Linear(h_dim, h_dim)\n",
        "        self.k_net = nn.Linear(h_dim, h_dim)\n",
        "        self.v_net = nn.Linear(h_dim, h_dim)\n",
        "\n",
        "        self.proj_net = nn.Linear(h_dim, h_dim)\n",
        "\n",
        "        self.att_drop = nn.Dropout(drop_p)\n",
        "        self.proj_drop = nn.Dropout(drop_p)\n",
        "\n",
        "        ones = torch.ones((max_T, max_T))\n",
        "        mask = torch.tril(ones).view(1, 1, max_T, max_T)\n",
        "\n",
        "        # register buffer makes sure mask does not get updated\n",
        "        # during backpropagation\n",
        "        self.register_buffer('mask',mask)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape # batch size, seq length, h_dim * n_heads\n",
        "\n",
        "        N, D = self.n_heads, C // self.n_heads # N = num heads, D = attention dim\n",
        "\n",
        "        # rearrange q, k, v as (B, N, T, D)\n",
        "        q = self.q_net(x).view(B, T, N, D).transpose(1,2)\n",
        "        k = self.k_net(x).view(B, T, N, D).transpose(1,2)\n",
        "        v = self.v_net(x).view(B, T, N, D).transpose(1,2)\n",
        "\n",
        "        # weights (B, N, T, T)\n",
        "        weights = q @ k.transpose(2,3) / math.sqrt(D)\n",
        "        # causal mask applied to weights\n",
        "        weights = weights.masked_fill(self.mask[...,:T,:T] == 0, float('-inf'))\n",
        "        # normalize weights, all -inf -> 0 after softmax\n",
        "        normalized_weights = F.softmax(weights, dim=-1)\n",
        "\n",
        "        # attention (B, N, T, D)\n",
        "        attention = self.att_drop(normalized_weights @ v)\n",
        "\n",
        "        # gather heads and project (B, N, T, D) -> (B, T, N*D)\n",
        "        attention = attention.transpose(1, 2).contiguous().view(B,T,N*D)\n",
        "\n",
        "        out = self.proj_drop(self.proj_net(attention))\n",
        "        return out\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, h_dim, max_T, n_heads, drop_p):\n",
        "        super().__init__()\n",
        "        self.attention = MaskedCausalAttention(h_dim, max_T, n_heads, drop_p)\n",
        "        self.mlp = nn.Sequential(\n",
        "                nn.Linear(h_dim, 4*h_dim),\n",
        "                nn.GELU(),\n",
        "                nn.Linear(4*h_dim, h_dim),\n",
        "                nn.Dropout(drop_p),\n",
        "            )\n",
        "        self.ln1 = nn.LayerNorm(h_dim)\n",
        "        self.ln2 = nn.LayerNorm(h_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Attention -> LayerNorm -> MLP -> LayerNorm\n",
        "        x = x + self.attention(x) # residual\n",
        "        x = self.ln1(x)\n",
        "        x = x + self.mlp(x) # residual\n",
        "        x = self.ln2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DecisionTransformer(nn.Module):\n",
        "    def __init__(self, state_dim, act_dim, n_blocks, h_dim, context_len, \n",
        "                 n_heads, drop_p, max_timestep=4096):\n",
        "        super().__init__()\n",
        "\n",
        "        self.state_dim = state_dim\n",
        "        self.act_dim = act_dim\n",
        "        self.h_dim = h_dim\n",
        "\n",
        "        ### transformer blocks\n",
        "        input_seq_len = 3 * context_len\n",
        "        blocks = [Block(h_dim, input_seq_len, n_heads, drop_p) for _ in range(n_blocks)]\n",
        "        self.transformer = nn.Sequential(*blocks)\n",
        "\n",
        "        ### projection heads (project to embedding)\n",
        "        self.embed_ln = nn.LayerNorm(h_dim)\n",
        "        self.embed_timestep = nn.Embedding(max_timestep, h_dim)\n",
        "        self.embed_rtg = torch.nn.Linear(1, h_dim)\n",
        "        self.embed_state = torch.nn.Linear(state_dim, h_dim)\n",
        "        \n",
        "        # # discrete actions\n",
        "        # self.embed_action = torch.nn.Embedding(act_dim, h_dim)\n",
        "        # use_action_tanh = False # False for discrete actions\n",
        "\n",
        "        # continuous actions\n",
        "        self.embed_action = torch.nn.Linear(act_dim, h_dim)\n",
        "        use_action_tanh = True # True for continuous actions\n",
        "        \n",
        "        ### prediction heads\n",
        "        self.predict_rtg = torch.nn.Linear(h_dim, 1)\n",
        "        self.predict_state = torch.nn.Linear(h_dim, state_dim)\n",
        "        self.predict_action = nn.Sequential(\n",
        "            *([nn.Linear(h_dim, act_dim)] + ([nn.Tanh()] if use_action_tanh else []))\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, timesteps, states, actions, returns_to_go):\n",
        "\n",
        "        B, T, _ = states.shape\n",
        "\n",
        "        time_embeddings = self.embed_timestep(timesteps)\n",
        "\n",
        "        # time embeddings are treated similar to positional embeddings\n",
        "        state_embeddings = self.embed_state(states) + time_embeddings\n",
        "        action_embeddings = self.embed_action(actions) + time_embeddings\n",
        "        returns_embeddings = self.embed_rtg(returns_to_go) + time_embeddings\n",
        "\n",
        "        # stack rtg, states and actions and reshape sequence as\n",
        "        # (r1, s1, a1, r2, s2, a2 ...)\n",
        "        h = torch.stack(\n",
        "            (returns_embeddings, state_embeddings, action_embeddings), dim=1\n",
        "        ).permute(0, 2, 1, 3).reshape(B, 3 * T, self.h_dim)\n",
        "\n",
        "        h = self.embed_ln(h)\n",
        "        \n",
        "        # transformer and prediction\n",
        "        h = self.transformer(h)\n",
        "\n",
        "        # get h reshaped such that its size = (B x 3 x T x h_dim) and\n",
        "        # h[:, 0, t] is conditioned on r_0, s_0, a_0 ... r_t\n",
        "        # h[:, 1, t] is conditioned on r_0, s_0, a_0 ... r_t, s_t\n",
        "        # h[:, 2, t] is conditioned on r_0, s_0, a_0 ... r_t, s_t, a_t\n",
        "        h = h.reshape(B, T, 3, self.h_dim).permute(0, 2, 1, 3)\n",
        "\n",
        "        # get predictions\n",
        "        return_preds = self.predict_rtg(h[:,2])     # predict next rtg given r, s, a\n",
        "        state_preds = self.predict_state(h[:,2])    # predict next state given r, s, a\n",
        "        action_preds = self.predict_action(h[:,1])  # predict action given r, s\n",
        "    \n",
        "        return state_preds, action_preds, return_preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLHjV3q28LNr"
      },
      "source": [
        "# infos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btnq_IL_j4PO"
      },
      "outputs": [],
      "source": [
        "## from infos.py from official d4rl github repo\n",
        "\n",
        "REF_MAX_SCORE = {\n",
        "    'halfcheetah' : 12135.0,\n",
        "    'walker2d' : 4592.3,\n",
        "    'hopper' : 3234.3,\n",
        "}\n",
        "\n",
        "REF_MIN_SCORE = {\n",
        "    'halfcheetah' : -280.178953,\n",
        "    'walker2d' : 1.629008,\n",
        "    'hopper' : -20.272305,\n",
        "}\n",
        "\n",
        "\n",
        "## calculated from d4rl datasets\n",
        "\n",
        "D4RL_DATASET_STATS = {\n",
        "        'halfcheetah-medium-v2': {\n",
        "                'state_mean':[-0.06845773756504059, 0.016414547339081764, -0.18354906141757965, \n",
        "                              -0.2762460708618164, -0.34061527252197266, -0.09339715540409088, \n",
        "                              -0.21321271359920502, -0.0877423882484436, 5.173007488250732, \n",
        "                              -0.04275195300579071, -0.036108363419771194, 0.14053793251514435, \n",
        "                              0.060498327016830444, 0.09550975263118744, 0.06739100068807602, \n",
        "                              0.005627387668937445, 0.013382787816226482\n",
        "                ],\n",
        "                'state_std':[0.07472999393939972, 0.3023499846458435, 0.30207309126853943, \n",
        "                             0.34417077898979187, 0.17619241774082184, 0.507205605506897, \n",
        "                             0.2567007839679718, 0.3294812738895416, 1.2574149370193481, \n",
        "                             0.7600541710853577, 1.9800915718078613, 6.565362453460693, \n",
        "                             7.466367721557617, 4.472222805023193, 10.566964149475098, \n",
        "                             5.671932697296143, 7.4982590675354  \n",
        "                ]\n",
        "            },\n",
        "        'halfcheetah-medium-replay-v2': {\n",
        "                'state_mean':[-0.12880703806877136, 0.3738119602203369, -0.14995987713336945, \n",
        "                              -0.23479078710079193, -0.2841278612613678, -0.13096535205841064, \n",
        "                              -0.20157982409000397, -0.06517726927995682, 3.4768247604370117, \n",
        "                              -0.02785065770149231, -0.015035249292850494, 0.07697279006242752, \n",
        "                              0.01266712136566639, 0.027325302362442017, 0.02316424623131752, \n",
        "                              0.010438721626996994, -0.015839405357837677\n",
        "                ],\n",
        "                'state_std':[0.17019015550613403, 1.284424901008606, 0.33442774415016174, \n",
        "                             0.3672759234905243, 0.26092398166656494, 0.4784106910228729, \n",
        "                             0.3181420564651489, 0.33552637696266174, 2.0931615829467773, \n",
        "                             0.8037433624267578, 1.9044333696365356, 6.573209762573242, \n",
        "                             7.572863578796387, 5.069749355316162, 9.10555362701416, \n",
        "                             6.085654258728027, 7.25300407409668\n",
        "                ]\n",
        "            },\n",
        "        'halfcheetah-medium-expert-v2': {\n",
        "                'state_mean':[-0.05667462572455406, 0.024369969964027405, -0.061670560389757156, \n",
        "                              -0.22351515293121338, -0.2675151228904724, -0.07545716315507889, \n",
        "                              -0.05809682980179787, -0.027675075456500053, 8.110626220703125, \n",
        "                              -0.06136331334710121, -0.17986927926540375, 0.25175222754478455, \n",
        "                              0.24186332523822784, 0.2519369423389435, 0.5879552960395813, \n",
        "                              -0.24090635776519775, -0.030184272676706314, 11.30526, 12.559462\n",
        "                ],\n",
        "                'state_std':[0.06103534251451492, 0.36054104566574097, 0.45544400811195374, \n",
        "                             0.38476887345314026, 0.2218363732099533, 0.5667523741722107, \n",
        "                             0.3196682929992676, 0.2852923572063446, 3.443821907043457, \n",
        "                             0.6728139519691467, 1.8616976737976074, 9.575807571411133, \n",
        "                             10.029894828796387, 5.903450012207031, 12.128185272216797, \n",
        "                             6.4811787605285645, 6.378620147705078, 10.343309, 11.868415\n",
        "                ]\n",
        "            },\n",
        "        'walker2d-medium-v2': {\n",
        "                'state_mean':[1.218966007232666, 0.14163373410701752, -0.03704913705587387, \n",
        "                              -0.13814310729503632, 0.5138224363327026, -0.04719110205769539, \n",
        "                              -0.47288352251052856, 0.042254164814949036, 2.3948874473571777, \n",
        "                              -0.03143199160695076, 0.04466355964541435, -0.023907244205474854, \n",
        "                              -0.1013401448726654, 0.09090937674045563, -0.004192637279629707, \n",
        "                              -0.12120571732521057, -0.5497063994407654\n",
        "                ],\n",
        "                'state_std':[0.12311358004808426, 0.3241879940032959, 0.11456084251403809, \n",
        "                             0.2623065710067749, 0.5640279054641724, 0.2271878570318222, \n",
        "                             0.3837319612503052, 0.7373676896095276, 1.2387926578521729, \n",
        "                             0.798020601272583, 1.5664079189300537, 1.8092705011367798, \n",
        "                             3.025604248046875, 4.062486171722412, 1.4586567878723145, \n",
        "                             3.7445690631866455, 5.5851287841796875\n",
        "                ]\n",
        "            },\n",
        "        'walker2d-medium-replay-v2': {\n",
        "                'state_mean':[1.209364652633667, 0.13264022767543793, -0.14371201395988464, \n",
        "                              -0.2046516090631485, 0.5577612519264221, -0.03231537342071533, \n",
        "                              -0.2784661054611206, 0.19130706787109375, 1.4701707363128662, \n",
        "                              -0.12504704296588898, 0.0564953051507473, -0.09991033375263214, \n",
        "                              -0.340340256690979, 0.03546293452382088, -0.08934258669614792, \n",
        "                              -0.2992438077926636, -0.5984178185462952   \n",
        "                ],\n",
        "                'state_std':[0.11929835379123688, 0.3562574088573456, 0.25852200388908386, \n",
        "                             0.42075422406196594, 0.5202291011810303, 0.15685082972049713, \n",
        "                             0.36770978569984436, 0.7161387801170349, 1.3763766288757324, \n",
        "                             0.8632221817970276, 2.6364643573760986, 3.0134117603302, \n",
        "                             3.720684051513672, 4.867283821105957, 2.6681625843048096, \n",
        "                             3.845186948776245, 5.4768385887146\n",
        "                ]\n",
        "            },\n",
        "        'walker2d-medium-expert-v2': {\n",
        "                'state_mean':[1.2294334173202515, 0.16869689524173737, -0.07089081406593323, \n",
        "                              -0.16197483241558075, 0.37101927399635315, -0.012209027074277401, \n",
        "                              -0.42461398243904114, 0.18986578285694122, 3.162475109100342, \n",
        "                              -0.018092676997184753, 0.03496946766972542, -0.013921679928898811, \n",
        "                              -0.05937029421329498, -0.19549426436424255, -0.0019200450042262673, \n",
        "                              -0.062483321875333786, -0.27366524934768677\n",
        "                ],\n",
        "                'state_std':[0.09932824969291687, 0.25981399416923523, 0.15062759816646576, \n",
        "                             0.24249176681041718, 0.6758718490600586, 0.1650741547346115, \n",
        "                             0.38140663504600525, 0.6962361335754395, 1.3501490354537964, \n",
        "                             0.7641991376876831, 1.534574270248413, 2.1785972118377686, \n",
        "                             3.276582717895508, 4.766193866729736, 1.1716983318328857, \n",
        "                             4.039782524108887, 5.891613960266113       \n",
        "                ]\n",
        "            },\n",
        "        'hopper-medium-v2': {\n",
        "                'state_mean':[1.311279058456421, -0.08469521254301071, -0.5382719039916992, \n",
        "                              -0.07201576232910156, 0.04932365566492081, 2.1066856384277344, \n",
        "                              -0.15017354488372803, 0.008783451281487942, -0.2848185896873474, \n",
        "                              -0.18540096282958984, -0.28461286425590515\n",
        "                ],\n",
        "                'state_std':[0.17790751159191132, 0.05444620922207832, 0.21297138929367065, \n",
        "                             0.14530418813228607, 0.6124444007873535, 0.8517446517944336, \n",
        "                             1.4515252113342285, 0.6751695871353149, 1.5362390279769897, \n",
        "                             1.616074562072754, 5.607253551483154 \n",
        "                ]\n",
        "            },\n",
        "        'hopper-medium-replay-v2': {\n",
        "                'state_mean':[1.2305138111114502, -0.04371410980820656, -0.44542956352233887, \n",
        "                              -0.09370097517967224, 0.09094487875699997, 1.3694725036621094, \n",
        "                              -0.19992674887180328, -0.022861352190375328, -0.5287045240402222, \n",
        "                              -0.14465883374214172, -0.19652697443962097      \n",
        "                ],\n",
        "                'state_std':[0.1756512075662613, 0.0636928603053093, 0.3438323438167572, \n",
        "                             0.19566889107227325, 0.5547984838485718, 1.051029920578003, \n",
        "                             1.158307671546936, 0.7963128685951233, 1.4802359342575073, \n",
        "                             1.6540331840515137, 5.108601093292236\n",
        "                ]\n",
        "            },\n",
        "        'hopper-medium-expert-v2': {\n",
        "                'state_mean':[1.3293815851211548, -0.09836531430482864, -0.5444297790527344, \n",
        "                              -0.10201650857925415, 0.02277466468513012, 2.3577215671539307, \n",
        "                              -0.06349576264619827, -0.00374026270583272, -0.1766270101070404, \n",
        "                              -0.11862941086292267, -0.12097819894552231\n",
        "                ],\n",
        "                'state_std':[0.17012375593185425, 0.05159067362546921, 0.18141433596611023, \n",
        "                             0.16430604457855225, 0.6023368239402771, 0.7737284898757935, \n",
        "                             1.4986555576324463, 0.7483318448066711, 1.7953159809112549, \n",
        "                             2.0530025959014893, 5.725032806396484\n",
        "                ]\n",
        "            },\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pewE01Ca4BG0"
      },
      "source": [
        "# utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaaymCHPlynF"
      },
      "outputs": [],
      "source": [
        "def discount_cumsum(x, gamma):\n",
        "    disc_cumsum = np.zeros_like(x)\n",
        "    disc_cumsum[-1] = x[-1]\n",
        "    for t in reversed(range(x.shape[0]-1)):\n",
        "        disc_cumsum[t] = x[t] + gamma * disc_cumsum[t+1]\n",
        "    return disc_cumsum\n",
        "\n",
        "\n",
        "def get_d4rl_dataset_stats(env_d4rl_name):\n",
        "    return D4RL_DATASET_STATS[env_d4rl_name]\n",
        "\n",
        "\n",
        "def get_d4rl_normalized_score(score, env_name):\n",
        "    env_key = env_name.split('-')[0].lower()\n",
        "    assert env_key in REF_MAX_SCORE, f'no reference score for {env_key} env to calculate d4rl score'\n",
        "    return (score - REF_MIN_SCORE[env_key]) / (REF_MAX_SCORE[env_key] - REF_MIN_SCORE[env_key])\n",
        "    \n",
        "    \n",
        "def evaluate_on_env(num_LTLs, feature_idx, c_list, model, device, context_len, \n",
        "                    env, rtg_target, rtg_scale,\n",
        "                    num_eval_ep=10, max_test_ep_len=1000,\n",
        "                    state_mean=None, state_std=None, render=False):\n",
        "\n",
        "    eval_batch_size = 1  # required for forward pass\n",
        "\n",
        "    results = {}\n",
        "    total_reward = 0\n",
        "    total_timesteps = 0\n",
        "\n",
        "    state_dim = env.observation_space.shape[0] + num_LTLs\n",
        "    act_dim = env.action_space.shape[0]\n",
        "\n",
        "    if state_mean is None:\n",
        "        state_mean = torch.zeros((state_dim,)).to(device)\n",
        "    else:\n",
        "        state_mean = torch.from_numpy(state_mean).to(device)\n",
        "        \n",
        "    if state_std is None:\n",
        "        state_std = torch.ones((state_dim,)).to(device)\n",
        "    else:\n",
        "        state_std = torch.from_numpy(state_std).to(device)\n",
        "\n",
        "    # same as timesteps used for training the transformer\n",
        "    # also, crashes if device is passed to arange()\n",
        "    timesteps = torch.arange(start=0, end=max_test_ep_len, step=1)\n",
        "    timesteps = timesteps.repeat(eval_batch_size, 1).to(device)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        results_dict = {}\n",
        "        for i in range(len(c_list) - 1):\n",
        "          results_dict[\"bin_\" + str(c_list[i]) + \"_\" + str(c_list[i+1])] = []\n",
        "\n",
        "\n",
        "        for _ in range(num_eval_ep):\n",
        "\n",
        "            # zeros place holders\n",
        "            actions = torch.zeros((eval_batch_size, max_test_ep_len, act_dim),\n",
        "                                dtype=torch.float32, device=device)\n",
        "\n",
        "            states = torch.zeros((eval_batch_size, max_test_ep_len, state_dim),\n",
        "                                dtype=torch.float32, device=device)\n",
        "            \n",
        "            rewards_to_go = torch.zeros((eval_batch_size, max_test_ep_len, 1),\n",
        "                                dtype=torch.float32, device=device)\n",
        "            \n",
        "            # init episode\n",
        "            running_state = env.reset()\n",
        "            \n",
        "            running_reward = 0\n",
        "            running_rtg = rtg_target / rtg_scale\n",
        "\n",
        "            # Set LTL specifications for episode\n",
        "            rand_int = np.random.randint(len(c_list) - 1)\n",
        "            c_min = c_list[rand_int]\n",
        "            c_max = c_list[rand_int + 1]\n",
        "            LTL_satisfied = False\n",
        "            LTL_satisfied_count = 0\n",
        "\n",
        "            assert num_LTLs == 2, \"np.append operation below assumes 2 LTLs\"\n",
        "            for t in range(max_test_ep_len):\n",
        "\n",
        "                total_timesteps += 1\n",
        "\n",
        "                # Add LTL specifications selected above.\n",
        "                # Once the LTL condition has been satisfied\n",
        "                # (that is, once the feature of interest lands in the 'bin' defined\n",
        "                # by the chosen c_min and c_max), the LTL specifications are set\n",
        "                # to 0 for the remainder of the trajectory.\n",
        "                if (running_state[feature_idx] > c_min) & (running_state[feature_idx] <= c_max):\n",
        "                  LTL_satisfied = True\n",
        "                  LTL_satisfied_count += 1\n",
        "                if LTL_satisfied:\n",
        "                  running_state = np.append(running_state, np.array([0., 0.]))\n",
        "                else:\n",
        "                  running_state = np.append(running_state, np.array([c_min, c_max]))\n",
        "                      \n",
        "                # add state in placeholder and normalize\n",
        "                states[0, t] = torch.from_numpy(running_state).to(device)\n",
        "                states[0, t] = (states[0, t] - state_mean) / state_std\n",
        "\n",
        "                # calcualate running rtg and add in placeholder\n",
        "                if LTL_satisfied_count == 1:\n",
        "                  running_rtg = running_rtg - (running_reward / rtg_scale) - (10/ rtg_scale)\n",
        "                else:\n",
        "                  running_rtg = running_rtg - (running_reward / rtg_scale)\n",
        "                rewards_to_go[0, t] = running_rtg\n",
        "\n",
        "                if t < context_len:\n",
        "                    _, act_preds, _ = model.forward(timesteps[:,:context_len],\n",
        "                                                states[:,:context_len],\n",
        "                                                actions[:,:context_len],\n",
        "                                                rewards_to_go[:,:context_len])\n",
        "                    act = act_preds[0, t].detach()\n",
        "                else:\n",
        "                    _, act_preds, _ = model.forward(timesteps[:,t-context_len+1:t+1],\n",
        "                                                states[:,t-context_len+1:t+1],\n",
        "                                                actions[:,t-context_len+1:t+1],\n",
        "                                                rewards_to_go[:,t-context_len+1:t+1])\n",
        "                    act = act_preds[0, -1].detach()\n",
        "\n",
        "\n",
        "                running_state, running_reward, done, _ = env.step(act.cpu().numpy())\n",
        "\n",
        "                # add action in placeholder\n",
        "                actions[0, t] = act\n",
        "\n",
        "                total_reward += running_reward\n",
        "\n",
        "                if render:\n",
        "                    env.render()\n",
        "                if done:\n",
        "                    break\n",
        "            if LTL_satisfied:\n",
        "              results_dict[\"bin_\" + str(c_min) + \"_\" + str(c_max)].append(1)\n",
        "            else:\n",
        "              results_dict[\"bin_\" + str(c_min) + \"_\" + str(c_max)].append(0)\n",
        "\n",
        "    for i in range(len(c_list) - 1):\n",
        "      successes = sum(results_dict[\"bin_\" + str(c_list[i]) + \"_\" + str(c_list[i+1])])\n",
        "      total = len(results_dict[\"bin_\" + str(c_list[i]) + \"_\" + str(c_list[i+1])])\n",
        "      print(f\"LTL success rate for bin {c_list[i], c_list[i+1]} (of {total} total cases): {successes/(total+0.0000001):.3f}\")\n",
        "    results['eval/avg_reward'] = total_reward / num_eval_ep\n",
        "    results['eval/avg_ep_len'] = total_timesteps / num_eval_ep\n",
        "    \n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXXrs_PjAHrN"
      },
      "source": [
        "# dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1Vb5rY_iiME",
        "outputId": "9871f99f-33fb-4372-db25-1eae0bb325f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/halfcheetah-medium-expert-v2.pkl\n",
            "num of trajectories in dataset:  2000\n",
            "minimum trajectory length in dataset:  1000\n",
            "state mean:  [-0.05667462572455406, 0.024369969964027405, -0.061670560389757156, -0.22351515293121338, -0.2675151228904724, -0.07545716315507889, -0.05809682980179787, -0.027675075456500053, 8.110626220703125, -0.06136331334710121, -0.17986927926540375, 0.25175222754478455, 0.24186332523822784, 0.2519369423389435, 0.5879552960395813, -0.24090635776519775, -0.030184272676706314]\n",
            "state std:  [0.06103534251451492, 0.36054104566574097, 0.45544400811195374, 0.38476887345314026, 0.2218363732099533, 0.5667523741722107, 0.3196682929992676, 0.2852923572063446, 3.443821907043457, 0.6728139519691467, 1.8616976737976074, 9.575807571411133, 10.029894828796387, 5.903450012207031, 12.128185272216797, 6.4811787605285645, 6.378620147705078]\n"
          ]
        }
      ],
      "source": [
        "## check data\n",
        "\n",
        "# load dataset\n",
        "with open(dataset_path, 'rb') as f:\n",
        "    trajectories = pickle.load(f)\n",
        "\n",
        "min_len = 10**4\n",
        "states = []\n",
        "for traj in trajectories:\n",
        "    min_len = min(min_len, traj['observations'].shape[0])\n",
        "    states.append(traj['observations'])\n",
        "\n",
        "# used for input normalization\n",
        "states = np.concatenate(states, axis=0)\n",
        "state_mean, state_std = np.mean(states, axis=0), np.std(states, axis=0) + 1e-6\n",
        "\n",
        "print(dataset_path)\n",
        "print(\"num of trajectories in dataset: \", len(trajectories))\n",
        "print(\"minimum trajectory length in dataset: \", min_len)\n",
        "print(\"state mean: \", state_mean.tolist())\n",
        "print(\"state std: \", state_std.tolist())\n",
        "\n",
        "## check if info is correct\n",
        "#print(\"is state mean info correct: \", state_mean.tolist() == D4RL_DATASET_STATS[env_d4rl_name]['state_mean'])\n",
        "#print(\"is state std info correct: \", state_std.tolist() == D4RL_DATASET_STATS[env_d4rl_name]['state_std'])\n",
        "\n",
        "#assert state_mean.tolist() == D4RL_DATASET_STATS[env_d4rl_name]['state_mean']\n",
        "#assert state_std.tolist() == D4RL_DATASET_STATS[env_d4rl_name]['state_std']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSRxFrFAcKlE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fcc4be9-ac8b-48e8-d875-e36f6efde933"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of trajectories is: 2000\n",
            "# of timesteps per trajectory is: 1000\n",
            "# of observations at each timestep is: 17\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f\"# of trajectories is: {len(trajectories)}\")\n",
        "print(f\"# of timesteps per trajectory is: {len(trajectories[0]['observations'])}\")\n",
        "print(f\"# of observations at each timestep is: {len(trajectories[0]['observations'][0])}\\n\")\n",
        "\n",
        "plot = False\n",
        "\n",
        "for feature_idx in range(17):\n",
        "  feature_max_val_list = []\n",
        "  for traj_idx in range(len(trajectories)):\n",
        "    all_feature_obs_in_traj = []\n",
        "    for tstep_idx in range(len(trajectories[traj_idx]['observations'])):\n",
        "      all_feature_obs_in_traj.append(trajectories[traj_idx]['observations'][tstep_idx][feature_idx])\n",
        "    feature_max_val_list.append(max(all_feature_obs_in_traj))\n",
        "  \n",
        "  if plot:\n",
        "    plt.hist(feature_max_val_list, bins=40)\n",
        "    plt.title(f'Histogram for Max Values in Feature #{feature_idx}')\n",
        "    plt.show()\n",
        "    plt.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmNrKBpJNCDy"
      },
      "outputs": [],
      "source": [
        "def get_c_vals(max_val, c_list):\n",
        "  \"\"\"\n",
        "  Returns the c_min and c_max based on the given c_list and \n",
        "  the given max_val from a trajectory\n",
        "  \"\"\"\n",
        "  bin_width = 2\n",
        "\n",
        "  # find the index of the value greater than or equal to the input number\n",
        "  c_max_idx = next((i for i, x in enumerate(c_list) if x >= max_val), len(c_list))\n",
        "  assert c_max_idx != 0, \"c_max is too low\"\n",
        "  assert c_max_idx < len(c_list), \"c_max is too high\"\n",
        "\n",
        "  c_min_idx = c_max_idx - 1\n",
        "  c_max = c_list[c_max_idx]\n",
        "  c_min = c_list[c_min_idx]\n",
        "  \n",
        "  return c_min, c_max\n",
        "\n",
        "\n",
        "def add_LTLs_to_trajectories(trajectories,\n",
        "                             feature_idx=8,\n",
        "                             c_list=[1., 11., 21.],\n",
        "                             num_LTLs=2,\n",
        "                             ):\n",
        "  \"\"\"\n",
        "  Appends the appropriate c_min and c_max values to the obesrvation\n",
        "  at each timestep in each trajectory prior to that trajectory's maximum value\n",
        "  being reached. \n",
        "  After the trajectory's max value is reached, appends 0, 0 to each observation\n",
        "  therafter in the trajectory.\n",
        "  \"\"\"\n",
        "  \n",
        "  for traj_idx in range(len(trajectories)):\n",
        "    # Construct a list of all the observations corresponding to the given \n",
        "    # feature in a trajectory\n",
        "    all_feature_obs_in_traj = []\n",
        "    for tstep_idx in range(len(trajectories[traj_idx]['observations'])):\n",
        "      all_feature_obs_in_traj.append(trajectories[traj_idx]['observations'][tstep_idx][feature_idx])\n",
        "    \n",
        "    # Find the max value and its index\n",
        "    max_val = max(all_feature_obs_in_traj)\n",
        "    max_idx = all_feature_obs_in_traj.index(max_val)\n",
        "    \n",
        "    # Identify the c_min and c_max based on the given max_val for given traj\n",
        "    c_min, c_max = get_c_vals(max_val, c_list)\n",
        "\n",
        "    # Add an extra reward for achieving the task\n",
        "\n",
        "    trajectories[traj_idx]['rewards'][max_idx] += 10\n",
        "\n",
        "    # Crete empty array where we'll build the LTL-augmented observations\n",
        "    # (later we'll replace the old observations with these)\n",
        "    num_tsteps = trajectories[traj_idx]['observations'].shape[0]\n",
        "    obs_dims = trajectories[traj_idx]['observations'].shape[1]\n",
        "    traj_updated_obs = np.empty(shape=(num_tsteps, obs_dims + num_LTLs), dtype=np.float32)\n",
        "\n",
        "    # Add appropriate LTL conditions to each observation in trajectory\n",
        "    assert num_LTLs == 2, \"Code here is specific to case of 2 LTL conditions (see 'new_obs = ' lines); if want more, need to modify\"\n",
        "    for tstep_idx in range(num_tsteps):\n",
        "\n",
        "      if tstep_idx <= max_idx:\n",
        "        # Append c_min and c_max to observations in traj before and at max_idx\n",
        "        new_obs = np.reshape(np.array(np.append(trajectories[traj_idx]['observations'][tstep_idx], c_min)), newshape=(1, obs_dims + 1))\n",
        "        new_obs = np.reshape(np.array(np.append(new_obs, c_max)), newshape=(1, obs_dims + 2))\n",
        "      else:\n",
        "        # Append 0. and 0. to observations in traj after max_idx\n",
        "        new_obs = np.reshape(np.array(np.append(trajectories[traj_idx]['observations'][tstep_idx], 0.)), newshape=(1, obs_dims + 1))\n",
        "        new_obs = np.reshape(np.array(np.append(new_obs, 0.)), newshape=(1, obs_dims + 2))\n",
        "      \n",
        "      traj_updated_obs[tstep_idx] = new_obs\n",
        "\n",
        "    # Check that datatypes of old and new observations are the same\n",
        "    dtype_in = trajectories[traj_idx]['observations'].dtype\n",
        "    dtype_out = traj_updated_obs.dtype\n",
        "    assert dtype_in == dtype_out, \"Dtypes are different!\"\n",
        "    \n",
        "    # Replace old observations for given traj w/ new observations\n",
        "    trajectories[traj_idx]['observations'] = traj_updated_obs\n",
        "\n",
        "  return trajectories\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eo4zPTjjn0Qr"
      },
      "outputs": [],
      "source": [
        "class D4RLTrajectoryDataset(Dataset):\n",
        "    def __init__(self, dataset_path, context_len, rtg_scale):\n",
        "\n",
        "        self.context_len = context_len        \n",
        "\n",
        "        # load dataset\n",
        "        with open(dataset_path, 'rb') as f:\n",
        "            self.trajectories = pickle.load(f)\n",
        "        \n",
        "        # add LTLs to trajectories\n",
        "        self.trajectories = add_LTLs_to_trajectories(self.trajectories)\n",
        "\n",
        "        # calculate min len of traj, state mean and variance\n",
        "        # and returns_to_go for all traj\n",
        "        min_len = 10**6\n",
        "        states = []\n",
        "        for traj in self.trajectories:\n",
        "            traj_len = traj['observations'].shape[0]\n",
        "            min_len = min(min_len, traj_len)\n",
        "            states.append(traj['observations'])\n",
        "            # calculate returns to go and rescale them\n",
        "            traj['returns_to_go'] = discount_cumsum(traj['rewards'], 1.0) / rtg_scale\n",
        "\n",
        "        # used for input normalization\n",
        "        states = np.concatenate(states, axis=0)\n",
        "        self.state_mean, self.state_std = np.mean(states, axis=0), np.std(states, axis=0) + 1e-6\n",
        "\n",
        "        # normalize states\n",
        "        for traj in self.trajectories:\n",
        "            traj['observations'] = (traj['observations'] - self.state_mean) / self.state_std\n",
        "\n",
        "\n",
        "    def get_state_stats(self):\n",
        "        return self.state_mean, self.state_std\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.trajectories)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        traj = self.trajectories[idx]\n",
        "        traj_len = traj['observations'].shape[0]\n",
        "\n",
        "        if traj_len >= self.context_len:\n",
        "            # sample random index to slice trajectory\n",
        "            si = random.randint(0, traj_len - self.context_len)\n",
        "\n",
        "            states = torch.from_numpy(traj['observations'][si : si + self.context_len])\n",
        "            actions = torch.from_numpy(traj['actions'][si : si + self.context_len])\n",
        "            returns_to_go = torch.from_numpy(traj['returns_to_go'][si : si + self.context_len])\n",
        "            timesteps = torch.arange(start=si, end=si+self.context_len, step=1)\n",
        "\n",
        "            # all ones since no padding\n",
        "            traj_mask = torch.ones(self.context_len, dtype=torch.long)\n",
        "\n",
        "        else:\n",
        "            padding_len = self.context_len - traj_len\n",
        "\n",
        "            # padding with zeros\n",
        "            states = torch.from_numpy(traj['observations'])\n",
        "            states = torch.cat([states,\n",
        "                                torch.zeros(([padding_len] + list(states.shape[1:])),\n",
        "                                dtype=states.dtype)], \n",
        "                               dim=0)\n",
        "            \n",
        "            actions = torch.from_numpy(traj['actions'])\n",
        "            actions = torch.cat([actions,\n",
        "                                torch.zeros(([padding_len] + list(actions.shape[1:])),\n",
        "                                dtype=actions.dtype)], \n",
        "                               dim=0)\n",
        "\n",
        "            returns_to_go = torch.from_numpy(traj['returns_to_go'])\n",
        "            returns_to_go = torch.cat([returns_to_go,\n",
        "                                torch.zeros(([padding_len] + list(returns_to_go.shape[1:])),\n",
        "                                dtype=returns_to_go.dtype)], \n",
        "                               dim=0)\n",
        "            \n",
        "            timesteps = torch.arange(start=0, end=self.context_len, step=1)\n",
        "\n",
        "            traj_mask = torch.cat([torch.ones(traj_len, dtype=torch.long), \n",
        "                                   torch.zeros(padding_len, dtype=torch.long)], \n",
        "                                  dim=0)\n",
        "            \n",
        "        return  timesteps, states, actions, returns_to_go, traj_mask\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7AK6T9Picu-"
      },
      "source": [
        "# train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GI9gwd8ylDdO",
        "outputId": "48fefa14-2a16-4ac8-99de-48c4bb916d04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "start time: 23-05-07-23-04-28\n",
            "============================================================\n",
            "device set to: cuda\n",
            "dataset path: data/halfcheetah-medium-expert-v2.pkl\n",
            "model save path: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "log csv save path: ./dt_runs/dt_halfcheetah-medium-expert-v2_log_23-05-07-23-04-28.csv\n"
          ]
        }
      ],
      "source": [
        "start_time = datetime.now().replace(microsecond=0)\n",
        "\n",
        "start_time_str = start_time.strftime(\"%y-%m-%d-%H-%M-%S\")\n",
        "\n",
        "prefix = \"dt_\" + env_d4rl_name\n",
        "\n",
        "save_model_name =  prefix + \"_model_\" + start_time_str + \".pt\"\n",
        "save_model_path = os.path.join(log_dir, save_model_name)\n",
        "save_best_model_path = save_model_path[:-3] + \"_best.pt\"\n",
        "\n",
        "log_csv_name = prefix + \"_log_\" + start_time_str + \".csv\"\n",
        "log_csv_path = os.path.join(log_dir, log_csv_name)\n",
        "\n",
        "\n",
        "csv_writer = csv.writer(open(log_csv_path, 'a', 1))\n",
        "csv_header = ([\"duration\", \"num_updates\", \"action_loss\", \n",
        "               \"eval_avg_reward\", \"eval_avg_ep_len\", \"eval_d4rl_score\"])\n",
        "\n",
        "csv_writer.writerow(csv_header)\n",
        "\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"start time: \" + start_time_str)\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"device set to: \" + str(device))\n",
        "print(\"dataset path: \" + dataset_path)\n",
        "print(\"model save path: \" + save_model_path)\n",
        "print(\"log csv save path: \" + log_csv_path)\n",
        "\n",
        "\n",
        "traj_dataset = D4RLTrajectoryDataset(dataset_path, context_len, rtg_scale)\n",
        "\n",
        "traj_data_loader = DataLoader(traj_dataset,\n",
        "\t\t\t\t\t\tbatch_size=batch_size,\n",
        "\t\t\t\t\t\tshuffle=True,\n",
        "\t\t\t\t\t\tpin_memory=True,\n",
        "\t\t\t\t\t\tdrop_last=True) \n",
        "\n",
        "data_iter = iter(traj_data_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RBLRM5nOVR_8",
        "outputId": "5b7b7a68-7e12-4754-8954-7883f1150d0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:01:25\n",
            "num of updates: 100\n",
            "action loss: 0.82625\n",
            "eval avg reward: -156.12844\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: -1.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:02:01\n",
            "num of updates: 200\n",
            "action loss: 0.78088\n",
            "eval avg reward: -129.87961\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 6 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 4 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:02:38\n",
            "num of updates: 300\n",
            "action loss: 0.70301\n",
            "eval avg reward: -109.98688\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:03:15\n",
            "num of updates: 400\n",
            "action loss: 0.61383\n",
            "eval avg reward: -109.46835\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:03:51\n",
            "num of updates: 500\n",
            "action loss: 0.52432\n",
            "eval avg reward: -104.12088\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:04:27\n",
            "num of updates: 600\n",
            "action loss: 0.43726\n",
            "eval avg reward: -116.79366\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 8 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 2 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:05:03\n",
            "num of updates: 700\n",
            "action loss: 0.36700\n",
            "eval avg reward: -99.78272\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 7 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 3 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:05:40\n",
            "num of updates: 800\n",
            "action loss: 0.31913\n",
            "eval avg reward: -88.36727\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:06:17\n",
            "num of updates: 900\n",
            "action loss: 0.29030\n",
            "eval avg reward: -58.63843\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 6 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 4 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:06:53\n",
            "num of updates: 1000\n",
            "action loss: 0.27114\n",
            "eval avg reward: -77.56762\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:07:28\n",
            "num of updates: 1100\n",
            "action loss: 0.25228\n",
            "eval avg reward: -56.51443\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:08:05\n",
            "num of updates: 1200\n",
            "action loss: 0.24000\n",
            "eval avg reward: -41.83521\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 7 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 3 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:08:43\n",
            "num of updates: 1300\n",
            "action loss: 0.22829\n",
            "eval avg reward: -29.51872\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:09:19\n",
            "num of updates: 1400\n",
            "action loss: 0.21497\n",
            "eval avg reward: 47.87434\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:09:55\n",
            "num of updates: 1500\n",
            "action loss: 0.20801\n",
            "eval avg reward: 128.28433\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 3 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 7 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:10:33\n",
            "num of updates: 1600\n",
            "action loss: 0.19872\n",
            "eval avg reward: 250.28602\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 6 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 4 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:11:09\n",
            "num of updates: 1700\n",
            "action loss: 0.19202\n",
            "eval avg reward: 488.84748\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 7 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 3 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:11:47\n",
            "num of updates: 1800\n",
            "action loss: 0.18474\n",
            "eval avg reward: 422.18302\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:12:23\n",
            "num of updates: 1900\n",
            "action loss: 0.17980\n",
            "eval avg reward: 1075.65347\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:12:59\n",
            "num of updates: 2000\n",
            "action loss: 0.17415\n",
            "eval avg reward: 865.39329\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:13:35\n",
            "num of updates: 2100\n",
            "action loss: 0.16835\n",
            "eval avg reward: 1174.01280\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 7 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 3 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:14:12\n",
            "num of updates: 2200\n",
            "action loss: 0.16463\n",
            "eval avg reward: 1340.39753\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 3 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 7 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:14:49\n",
            "num of updates: 2300\n",
            "action loss: 0.16103\n",
            "eval avg reward: 1561.72347\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 7 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 3 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:15:24\n",
            "num of updates: 2400\n",
            "action loss: 0.15789\n",
            "eval avg reward: 1176.00222\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:16:00\n",
            "num of updates: 2500\n",
            "action loss: 0.15370\n",
            "eval avg reward: 1057.65365\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 7 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 3 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:16:36\n",
            "num of updates: 2600\n",
            "action loss: 0.15147\n",
            "eval avg reward: 530.02822\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:17:13\n",
            "num of updates: 2700\n",
            "action loss: 0.14753\n",
            "eval avg reward: 1235.78853\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:17:49\n",
            "num of updates: 2800\n",
            "action loss: 0.14395\n",
            "eval avg reward: 923.72189\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:18:25\n",
            "num of updates: 2900\n",
            "action loss: 0.14174\n",
            "eval avg reward: 708.60778\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 7 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 3 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:19:00\n",
            "num of updates: 3000\n",
            "action loss: 0.13761\n",
            "eval avg reward: 562.99274\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 6 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 4 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:19:36\n",
            "num of updates: 3100\n",
            "action loss: 0.13604\n",
            "eval avg reward: 899.25903\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 6 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 4 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:20:11\n",
            "num of updates: 3200\n",
            "action loss: 0.13313\n",
            "eval avg reward: 417.91308\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 7 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 3 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:20:48\n",
            "num of updates: 3300\n",
            "action loss: 0.13055\n",
            "eval avg reward: 819.92201\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 7 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 3 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:21:24\n",
            "num of updates: 3400\n",
            "action loss: 0.12666\n",
            "eval avg reward: 551.53721\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:22:00\n",
            "num of updates: 3500\n",
            "action loss: 0.12393\n",
            "eval avg reward: 408.48345\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:22:35\n",
            "num of updates: 3600\n",
            "action loss: 0.12217\n",
            "eval avg reward: 642.15190\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 8 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 2 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:23:11\n",
            "num of updates: 3700\n",
            "action loss: 0.11827\n",
            "eval avg reward: 348.28063\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:23:47\n",
            "num of updates: 3800\n",
            "action loss: 0.11826\n",
            "eval avg reward: 423.10044\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:24:24\n",
            "num of updates: 3900\n",
            "action loss: 0.11499\n",
            "eval avg reward: 1018.72842\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 6 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 4 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:25:00\n",
            "num of updates: 4000\n",
            "action loss: 0.11301\n",
            "eval avg reward: 887.57353\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 6 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 4 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:25:35\n",
            "num of updates: 4100\n",
            "action loss: 0.11166\n",
            "eval avg reward: 742.43515\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:26:11\n",
            "num of updates: 4200\n",
            "action loss: 0.10892\n",
            "eval avg reward: 743.67778\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 2 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 8 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:26:47\n",
            "num of updates: 4300\n",
            "action loss: 0.10728\n",
            "eval avg reward: 1170.62835\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 3 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 7 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:27:24\n",
            "num of updates: 4400\n",
            "action loss: 0.10721\n",
            "eval avg reward: 1615.57317\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 8 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 2 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:28:00\n",
            "num of updates: 4500\n",
            "action loss: 0.10379\n",
            "eval avg reward: 786.90421\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 6 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 4 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:28:35\n",
            "num of updates: 4600\n",
            "action loss: 0.10220\n",
            "eval avg reward: 1117.26791\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 6 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 4 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:29:10\n",
            "num of updates: 4700\n",
            "action loss: 0.10116\n",
            "eval avg reward: 826.48334\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 6 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 4 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:29:46\n",
            "num of updates: 4800\n",
            "action loss: 0.09916\n",
            "eval avg reward: 1139.74742\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:30:22\n",
            "num of updates: 4900\n",
            "action loss: 0.09971\n",
            "eval avg reward: 1865.88793\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:30:59\n",
            "num of updates: 5000\n",
            "action loss: 0.09620\n",
            "eval avg reward: 969.84938\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 3 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 7 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:31:35\n",
            "num of updates: 5100\n",
            "action loss: 0.09460\n",
            "eval avg reward: 1258.31422\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 3 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 7 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:32:10\n",
            "num of updates: 5200\n",
            "action loss: 0.09309\n",
            "eval avg reward: 1297.70730\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:32:46\n",
            "num of updates: 5300\n",
            "action loss: 0.09167\n",
            "eval avg reward: 1594.34017\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 3 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 7 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:33:22\n",
            "num of updates: 5400\n",
            "action loss: 0.09091\n",
            "eval avg reward: 1118.90229\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:33:59\n",
            "num of updates: 5500\n",
            "action loss: 0.08880\n",
            "eval avg reward: 2047.59272\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 6 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 4 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:34:35\n",
            "num of updates: 5600\n",
            "action loss: 0.08746\n",
            "eval avg reward: 2393.32278\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 2 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 8 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:35:11\n",
            "num of updates: 5700\n",
            "action loss: 0.08614\n",
            "eval avg reward: 2736.16262\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:35:46\n",
            "num of updates: 5800\n",
            "action loss: 0.08476\n",
            "eval avg reward: 2638.94971\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:36:22\n",
            "num of updates: 5900\n",
            "action loss: 0.08310\n",
            "eval avg reward: 2503.75567\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:36:59\n",
            "num of updates: 6000\n",
            "action loss: 0.08228\n",
            "eval avg reward: 2696.93714\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:37:35\n",
            "num of updates: 6100\n",
            "action loss: 0.08039\n",
            "eval avg reward: 1910.22937\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:38:11\n",
            "num of updates: 6200\n",
            "action loss: 0.08053\n",
            "eval avg reward: 2492.63861\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:38:47\n",
            "num of updates: 6300\n",
            "action loss: 0.07926\n",
            "eval avg reward: 3077.17345\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:39:22\n",
            "num of updates: 6400\n",
            "action loss: 0.07760\n",
            "eval avg reward: 3754.77658\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:39:59\n",
            "num of updates: 6500\n",
            "action loss: 0.07623\n",
            "eval avg reward: 3867.15801\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 6 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 4 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:40:36\n",
            "num of updates: 6600\n",
            "action loss: 0.07582\n",
            "eval avg reward: 3223.27046\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 7 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 3 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:41:11\n",
            "num of updates: 6700\n",
            "action loss: 0.07481\n",
            "eval avg reward: 4488.50749\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 6 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 4 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:41:47\n",
            "num of updates: 6800\n",
            "action loss: 0.07305\n",
            "eval avg reward: 2897.14212\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:42:23\n",
            "num of updates: 6900\n",
            "action loss: 0.07235\n",
            "eval avg reward: 3852.15340\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:42:59\n",
            "num of updates: 7000\n",
            "action loss: 0.07165\n",
            "eval avg reward: 3414.84158\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:43:36\n",
            "num of updates: 7100\n",
            "action loss: 0.07106\n",
            "eval avg reward: 4007.91794\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:44:12\n",
            "num of updates: 7200\n",
            "action loss: 0.07077\n",
            "eval avg reward: 3745.54138\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 6 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 4 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:44:47\n",
            "num of updates: 7300\n",
            "action loss: 0.06878\n",
            "eval avg reward: 3762.06672\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:45:23\n",
            "num of updates: 7400\n",
            "action loss: 0.06904\n",
            "eval avg reward: 3501.45056\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:45:58\n",
            "num of updates: 7500\n",
            "action loss: 0.06830\n",
            "eval avg reward: 3073.10797\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:46:35\n",
            "num of updates: 7600\n",
            "action loss: 0.06753\n",
            "eval avg reward: 3520.06725\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:47:11\n",
            "num of updates: 7700\n",
            "action loss: 0.06616\n",
            "eval avg reward: 2890.05127\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 3 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 7 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:47:47\n",
            "num of updates: 7800\n",
            "action loss: 0.06557\n",
            "eval avg reward: 2860.18899\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 7 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 3 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:48:22\n",
            "num of updates: 7900\n",
            "action loss: 0.06509\n",
            "eval avg reward: 3389.91145\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:48:58\n",
            "num of updates: 8000\n",
            "action loss: 0.06534\n",
            "eval avg reward: 3129.60848\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:49:33\n",
            "num of updates: 8100\n",
            "action loss: 0.06426\n",
            "eval avg reward: 3274.86307\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:50:11\n",
            "num of updates: 8200\n",
            "action loss: 0.06312\n",
            "eval avg reward: 2926.51437\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:50:46\n",
            "num of updates: 8300\n",
            "action loss: 0.06344\n",
            "eval avg reward: 4297.94376\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:51:22\n",
            "num of updates: 8400\n",
            "action loss: 0.06178\n",
            "eval avg reward: 3989.65538\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:51:57\n",
            "num of updates: 8500\n",
            "action loss: 0.06222\n",
            "eval avg reward: 3283.75265\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:52:33\n",
            "num of updates: 8600\n",
            "action loss: 0.06072\n",
            "eval avg reward: 2652.05081\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:53:12\n",
            "num of updates: 8700\n",
            "action loss: 0.06086\n",
            "eval avg reward: 2763.63117\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:53:49\n",
            "num of updates: 8800\n",
            "action loss: 0.06018\n",
            "eval avg reward: 3608.80952\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:54:25\n",
            "num of updates: 8900\n",
            "action loss: 0.06007\n",
            "eval avg reward: 4561.06252\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 3 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 7 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:55:00\n",
            "num of updates: 9000\n",
            "action loss: 0.05919\n",
            "eval avg reward: 4680.87534\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 1 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 9 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:55:36\n",
            "num of updates: 9100\n",
            "action loss: 0.05882\n",
            "eval avg reward: 3599.84420\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 2 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 8 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:56:13\n",
            "num of updates: 9200\n",
            "action loss: 0.05885\n",
            "eval avg reward: 3504.40564\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:56:49\n",
            "num of updates: 9300\n",
            "action loss: 0.05801\n",
            "eval avg reward: 4257.98761\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:57:25\n",
            "num of updates: 9400\n",
            "action loss: 0.05753\n",
            "eval avg reward: 3495.99171\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:58:00\n",
            "num of updates: 9500\n",
            "action loss: 0.05712\n",
            "eval avg reward: 3733.26612\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 6 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 4 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:58:36\n",
            "num of updates: 9600\n",
            "action loss: 0.05693\n",
            "eval avg reward: 3863.28508\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 6 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 4 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:59:12\n",
            "num of updates: 9700\n",
            "action loss: 0.05603\n",
            "eval avg reward: 4080.21894\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 8 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 2 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 0:59:49\n",
            "num of updates: 9800\n",
            "action loss: 0.05573\n",
            "eval avg reward: 4632.36127\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 3 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 7 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 1:00:24\n",
            "num of updates: 9900\n",
            "action loss: 0.05514\n",
            "eval avg reward: 3360.50241\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 6 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 4 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 1:01:00\n",
            "num of updates: 10000\n",
            "action loss: 0.05437\n",
            "eval avg reward: 5101.13599\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 1:01:35\n",
            "num of updates: 10100\n",
            "action loss: 0.05395\n",
            "eval avg reward: 4720.28654\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 1:02:11\n",
            "num of updates: 10200\n",
            "action loss: 0.05420\n",
            "eval avg reward: 4345.17148\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 1 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 9 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 1:02:48\n",
            "num of updates: 10300\n",
            "action loss: 0.05367\n",
            "eval avg reward: 4048.83126\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 1:03:24\n",
            "num of updates: 10400\n",
            "action loss: 0.05373\n",
            "eval avg reward: 4112.08921\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 1:04:00\n",
            "num of updates: 10500\n",
            "action loss: 0.05349\n",
            "eval avg reward: 4943.90308\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 1:04:36\n",
            "num of updates: 10600\n",
            "action loss: 0.05341\n",
            "eval avg reward: 4466.18402\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 6 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 4 total cases): 0.250\n",
            "============================================================\n",
            "time elapsed: 1:05:11\n",
            "num of updates: 10700\n",
            "action loss: 0.05365\n",
            "eval avg reward: 4357.39649\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 6 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 4 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 1:05:47\n",
            "num of updates: 10800\n",
            "action loss: 0.05241\n",
            "eval avg reward: 4993.92306\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 7 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 3 total cases): 0.333\n",
            "============================================================\n",
            "time elapsed: 1:06:24\n",
            "num of updates: 10900\n",
            "action loss: 0.05165\n",
            "eval avg reward: 5136.81293\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 7 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 3 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 1:07:00\n",
            "num of updates: 11000\n",
            "action loss: 0.05244\n",
            "eval avg reward: 4468.04958\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.400\n",
            "============================================================\n",
            "time elapsed: 1:07:35\n",
            "num of updates: 11100\n",
            "action loss: 0.05151\n",
            "eval avg reward: 4056.64272\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 6 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 4 total cases): 0.250\n",
            "============================================================\n",
            "time elapsed: 1:08:11\n",
            "num of updates: 11200\n",
            "action loss: 0.05081\n",
            "eval avg reward: 3845.01407\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 0.167\n",
            "============================================================\n",
            "time elapsed: 1:08:47\n",
            "num of updates: 11300\n",
            "action loss: 0.05138\n",
            "eval avg reward: 4366.29283\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.200\n",
            "============================================================\n",
            "time elapsed: 1:09:23\n",
            "num of updates: 11400\n",
            "action loss: 0.05078\n",
            "eval avg reward: 3752.63516\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 8 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 2 total cases): 0.000\n",
            "============================================================\n",
            "time elapsed: 1:09:59\n",
            "num of updates: 11500\n",
            "action loss: 0.05038\n",
            "eval avg reward: 4204.24269\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 2 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 8 total cases): 0.250\n",
            "============================================================\n",
            "time elapsed: 1:10:35\n",
            "num of updates: 11600\n",
            "action loss: 0.05047\n",
            "eval avg reward: 5005.65857\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 0.333\n",
            "============================================================\n",
            "time elapsed: 1:11:10\n",
            "num of updates: 11700\n",
            "action loss: 0.04952\n",
            "eval avg reward: 4363.84246\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 1 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 9 total cases): 0.333\n",
            "============================================================\n",
            "time elapsed: 1:11:46\n",
            "num of updates: 11800\n",
            "action loss: 0.04990\n",
            "eval avg reward: 3751.52324\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 3 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 7 total cases): 0.143\n",
            "============================================================\n",
            "time elapsed: 1:12:22\n",
            "num of updates: 11900\n",
            "action loss: 0.04950\n",
            "eval avg reward: 4288.84998\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.800\n",
            "============================================================\n",
            "time elapsed: 1:12:59\n",
            "num of updates: 12000\n",
            "action loss: 0.04894\n",
            "eval avg reward: 5391.73055\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 0.333\n",
            "============================================================\n",
            "time elapsed: 1:13:34\n",
            "num of updates: 12100\n",
            "action loss: 0.04910\n",
            "eval avg reward: 4841.62650\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 7 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 3 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:14:10\n",
            "num of updates: 12200\n",
            "action loss: 0.04866\n",
            "eval avg reward: 5098.34964\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 3 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 7 total cases): 0.143\n",
            "============================================================\n",
            "time elapsed: 1:14:45\n",
            "num of updates: 12300\n",
            "action loss: 0.04819\n",
            "eval avg reward: 4039.34602\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 3 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 7 total cases): 0.857\n",
            "============================================================\n",
            "time elapsed: 1:15:21\n",
            "num of updates: 12400\n",
            "action loss: 0.04805\n",
            "eval avg reward: 4801.80358\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 3 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 7 total cases): 0.857\n",
            "============================================================\n",
            "time elapsed: 1:15:58\n",
            "num of updates: 12500\n",
            "action loss: 0.04840\n",
            "eval avg reward: 5764.90868\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.800\n",
            "============================================================\n",
            "time elapsed: 1:16:34\n",
            "num of updates: 12600\n",
            "action loss: 0.04816\n",
            "eval avg reward: 5402.43651\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.800\n",
            "============================================================\n",
            "time elapsed: 1:17:09\n",
            "num of updates: 12700\n",
            "action loss: 0.04822\n",
            "eval avg reward: 4881.10005\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 3 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 7 total cases): 0.286\n",
            "============================================================\n",
            "time elapsed: 1:17:45\n",
            "num of updates: 12800\n",
            "action loss: 0.04765\n",
            "eval avg reward: 4414.04227\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 8 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 2 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:18:21\n",
            "num of updates: 12900\n",
            "action loss: 0.04762\n",
            "eval avg reward: 5286.88329\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 0.833\n",
            "============================================================\n",
            "time elapsed: 1:18:57\n",
            "num of updates: 13000\n",
            "action loss: 0.04807\n",
            "eval avg reward: 4557.03018\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.800\n",
            "============================================================\n",
            "time elapsed: 1:19:34\n",
            "num of updates: 13100\n",
            "action loss: 0.04661\n",
            "eval avg reward: 5380.95891\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 2 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 8 total cases): 0.750\n",
            "============================================================\n",
            "time elapsed: 1:20:09\n",
            "num of updates: 13200\n",
            "action loss: 0.04720\n",
            "eval avg reward: 5478.30161\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.800\n",
            "============================================================\n",
            "time elapsed: 1:20:44\n",
            "num of updates: 13300\n",
            "action loss: 0.04675\n",
            "eval avg reward: 4885.61324\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 3 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 7 total cases): 0.857\n",
            "============================================================\n",
            "time elapsed: 1:21:20\n",
            "num of updates: 13400\n",
            "action loss: 0.04597\n",
            "eval avg reward: 4708.07946\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.800\n",
            "============================================================\n",
            "time elapsed: 1:21:56\n",
            "num of updates: 13500\n",
            "action loss: 0.04753\n",
            "eval avg reward: 4688.59623\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 3 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 7 total cases): 0.429\n",
            "============================================================\n",
            "time elapsed: 1:22:33\n",
            "num of updates: 13600\n",
            "action loss: 0.04590\n",
            "eval avg reward: 4928.52928\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:23:09\n",
            "num of updates: 13700\n",
            "action loss: 0.04631\n",
            "eval avg reward: 5337.28324\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 8 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 2 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:23:44\n",
            "num of updates: 13800\n",
            "action loss: 0.04572\n",
            "eval avg reward: 5321.59878\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.800\n",
            "============================================================\n",
            "time elapsed: 1:24:20\n",
            "num of updates: 13900\n",
            "action loss: 0.04574\n",
            "eval avg reward: 5433.45654\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 0.667\n",
            "============================================================\n",
            "time elapsed: 1:24:55\n",
            "num of updates: 14000\n",
            "action loss: 0.04588\n",
            "eval avg reward: 5201.94103\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 0.667\n",
            "============================================================\n",
            "time elapsed: 1:25:32\n",
            "num of updates: 14100\n",
            "action loss: 0.04594\n",
            "eval avg reward: 4047.98909\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 7 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 3 total cases): 0.667\n",
            "============================================================\n",
            "time elapsed: 1:26:09\n",
            "num of updates: 14200\n",
            "action loss: 0.04534\n",
            "eval avg reward: 4993.22600\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 3 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 7 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:26:45\n",
            "num of updates: 14300\n",
            "action loss: 0.04513\n",
            "eval avg reward: 5561.54160\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 7 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 3 total cases): 0.667\n",
            "============================================================\n",
            "time elapsed: 1:27:21\n",
            "num of updates: 14400\n",
            "action loss: 0.04537\n",
            "eval avg reward: 5466.84867\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:27:57\n",
            "num of updates: 14500\n",
            "action loss: 0.04504\n",
            "eval avg reward: 5695.66546\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 6 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 4 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:28:33\n",
            "num of updates: 14600\n",
            "action loss: 0.04383\n",
            "eval avg reward: 5177.41023\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 6 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 4 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:29:10\n",
            "num of updates: 14700\n",
            "action loss: 0.04467\n",
            "eval avg reward: 5506.63294\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 7 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 3 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:29:46\n",
            "num of updates: 14800\n",
            "action loss: 0.04488\n",
            "eval avg reward: 5483.06825\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:30:22\n",
            "num of updates: 14900\n",
            "action loss: 0.04459\n",
            "eval avg reward: 5145.63028\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:30:57\n",
            "num of updates: 15000\n",
            "action loss: 0.04396\n",
            "eval avg reward: 5601.44786\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 0.833\n",
            "============================================================\n",
            "time elapsed: 1:31:33\n",
            "num of updates: 15100\n",
            "action loss: 0.04378\n",
            "eval avg reward: 5357.35323\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 6 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 4 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:32:10\n",
            "num of updates: 15200\n",
            "action loss: 0.04342\n",
            "eval avg reward: 4658.30632\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:32:46\n",
            "num of updates: 15300\n",
            "action loss: 0.04360\n",
            "eval avg reward: 5374.71974\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:33:22\n",
            "num of updates: 15400\n",
            "action loss: 0.04394\n",
            "eval avg reward: 4772.59790\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 6 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 4 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:33:58\n",
            "num of updates: 15500\n",
            "action loss: 0.04418\n",
            "eval avg reward: 5402.81843\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.800\n",
            "============================================================\n",
            "time elapsed: 1:34:34\n",
            "num of updates: 15600\n",
            "action loss: 0.04302\n",
            "eval avg reward: 4885.51819\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 6 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 4 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:35:10\n",
            "num of updates: 15700\n",
            "action loss: 0.04327\n",
            "eval avg reward: 5294.80438\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:35:47\n",
            "num of updates: 15800\n",
            "action loss: 0.04337\n",
            "eval avg reward: 5745.58668\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 0.800\n",
            "============================================================\n",
            "time elapsed: 1:36:22\n",
            "num of updates: 15900\n",
            "action loss: 0.04307\n",
            "eval avg reward: 5274.19504\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 7 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 3 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:36:58\n",
            "num of updates: 16000\n",
            "action loss: 0.04320\n",
            "eval avg reward: 5408.43809\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 7 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 3 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:37:34\n",
            "num of updates: 16100\n",
            "action loss: 0.04302\n",
            "eval avg reward: 5069.30799\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:38:10\n",
            "num of updates: 16200\n",
            "action loss: 0.04341\n",
            "eval avg reward: 4737.78044\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 2 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 8 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:38:47\n",
            "num of updates: 16300\n",
            "action loss: 0.04229\n",
            "eval avg reward: 5902.02519\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:39:23\n",
            "num of updates: 16400\n",
            "action loss: 0.04280\n",
            "eval avg reward: 4834.39725\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:39:59\n",
            "num of updates: 16500\n",
            "action loss: 0.04256\n",
            "eval avg reward: 5176.02591\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:40:34\n",
            "num of updates: 16600\n",
            "action loss: 0.04212\n",
            "eval avg reward: 5644.44939\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 3 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 7 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:41:11\n",
            "num of updates: 16700\n",
            "action loss: 0.04191\n",
            "eval avg reward: 4435.80143\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:41:48\n",
            "num of updates: 16800\n",
            "action loss: 0.04261\n",
            "eval avg reward: 5622.29607\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:42:24\n",
            "num of updates: 16900\n",
            "action loss: 0.04244\n",
            "eval avg reward: 4451.40933\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 8 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 2 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:43:00\n",
            "num of updates: 17000\n",
            "action loss: 0.04240\n",
            "eval avg reward: 5331.68545\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 0.833\n",
            "============================================================\n",
            "time elapsed: 1:43:35\n",
            "num of updates: 17100\n",
            "action loss: 0.04246\n",
            "eval avg reward: 5234.67789\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 3 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 7 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:44:11\n",
            "num of updates: 17200\n",
            "action loss: 0.04214\n",
            "eval avg reward: 5666.92375\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 6 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 4 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:44:48\n",
            "num of updates: 17300\n",
            "action loss: 0.04207\n",
            "eval avg reward: 5282.26643\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 3 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 7 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:45:25\n",
            "num of updates: 17400\n",
            "action loss: 0.04163\n",
            "eval avg reward: 5611.35763\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:46:00\n",
            "num of updates: 17500\n",
            "action loss: 0.04191\n",
            "eval avg reward: 5766.03407\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 7 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 3 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:46:36\n",
            "num of updates: 17600\n",
            "action loss: 0.04173\n",
            "eval avg reward: 5480.57980\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 8 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 2 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:47:12\n",
            "num of updates: 17700\n",
            "action loss: 0.04104\n",
            "eval avg reward: 5356.13139\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 3 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 7 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:47:49\n",
            "num of updates: 17800\n",
            "action loss: 0.04210\n",
            "eval avg reward: 5820.90427\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:48:26\n",
            "num of updates: 17900\n",
            "action loss: 0.04113\n",
            "eval avg reward: 4451.17834\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 6 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 4 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:49:02\n",
            "num of updates: 18000\n",
            "action loss: 0.04108\n",
            "eval avg reward: 5504.66119\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 7 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 3 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:49:38\n",
            "num of updates: 18100\n",
            "action loss: 0.04114\n",
            "eval avg reward: 4936.63175\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 8 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 2 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:50:14\n",
            "num of updates: 18200\n",
            "action loss: 0.04127\n",
            "eval avg reward: 4933.91319\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:50:50\n",
            "num of updates: 18300\n",
            "action loss: 0.04147\n",
            "eval avg reward: 5376.48474\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 9 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 1 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:51:27\n",
            "num of updates: 18400\n",
            "action loss: 0.04051\n",
            "eval avg reward: 5151.41779\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 2 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 8 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:52:03\n",
            "num of updates: 18500\n",
            "action loss: 0.04042\n",
            "eval avg reward: 5429.44713\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:52:38\n",
            "num of updates: 18600\n",
            "action loss: 0.04128\n",
            "eval avg reward: 5415.29430\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 7 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 3 total cases): 0.667\n",
            "============================================================\n",
            "time elapsed: 1:53:14\n",
            "num of updates: 18700\n",
            "action loss: 0.04101\n",
            "eval avg reward: 4140.24957\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 8 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 2 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:53:50\n",
            "num of updates: 18800\n",
            "action loss: 0.04091\n",
            "eval avg reward: 5171.64966\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 6 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 4 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:54:28\n",
            "num of updates: 18900\n",
            "action loss: 0.04125\n",
            "eval avg reward: 5310.42197\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:55:03\n",
            "num of updates: 19000\n",
            "action loss: 0.03992\n",
            "eval avg reward: 4721.08338\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:55:39\n",
            "num of updates: 19100\n",
            "action loss: 0.04101\n",
            "eval avg reward: 5215.86743\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:56:15\n",
            "num of updates: 19200\n",
            "action loss: 0.04126\n",
            "eval avg reward: 5604.17222\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:56:50\n",
            "num of updates: 19300\n",
            "action loss: 0.03996\n",
            "eval avg reward: 5770.11231\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 2 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 8 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:57:27\n",
            "num of updates: 19400\n",
            "action loss: 0.03960\n",
            "eval avg reward: 5897.38020\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 7 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 3 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:58:03\n",
            "num of updates: 19500\n",
            "action loss: 0.03993\n",
            "eval avg reward: 5451.74944\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:58:39\n",
            "num of updates: 19600\n",
            "action loss: 0.03994\n",
            "eval avg reward: 5705.17443\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 7 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 3 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:59:15\n",
            "num of updates: 19700\n",
            "action loss: 0.03925\n",
            "eval avg reward: 5427.32005\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 1:59:50\n",
            "num of updates: 19800\n",
            "action loss: 0.04005\n",
            "eval avg reward: 5554.48734\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 5 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 5 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 2:00:27\n",
            "num of updates: 19900\n",
            "action loss: 0.03970\n",
            "eval avg reward: 5705.62581\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 4 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 6 total cases): 1.000\n",
            "============================================================\n",
            "time elapsed: 2:01:04\n",
            "num of updates: 20000\n",
            "action loss: 0.03950\n",
            "eval avg reward: 5497.85675\n",
            "eval avg ep len: 1000.00000\n",
            "eval d4rl score: 10.00000\n",
            "max d4rl score: 10.00000\n",
            "saving max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saving current model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "============================================================\n",
            "finished training!\n",
            "============================================================\n",
            "started training at: 23-05-07-23-04-28\n",
            "finished training at: 23-05-08-01-05-32\n",
            "total training time: 2:01:04\n",
            "max d4rl score: 10.00000\n",
            "saved max d4rl score model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "saved last updated model at: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_efdec3ee-bd65-46ff-b500-ef4ab145bf73\", \"dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\", 4575795)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best model downloaded locally\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_475b3fe2-c724-4ffd-b58b-3b748508f888\", \"dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28.pt\", 4575327)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "most recent model downloaded locally\n"
          ]
        }
      ],
      "source": [
        "## get state stats from dataset\n",
        "state_mean, state_std = traj_dataset.get_state_stats()\n",
        "\n",
        "env = gym.make(env_name)\n",
        "\n",
        "num_LTLs = 2\n",
        "feature_idx = 8\n",
        "c_list=[1., 11., 21.]\n",
        "\n",
        "\n",
        "state_dim = env.observation_space.shape[0] + num_LTLs\n",
        "act_dim = env.action_space.shape[0]\n",
        "\n",
        "model = DecisionTransformer(\n",
        "\t\t\tstate_dim=state_dim,\n",
        "\t\t\tact_dim=act_dim,\n",
        "\t\t\tn_blocks=n_blocks,\n",
        "\t\t\th_dim=embed_dim,\n",
        "\t\t\tcontext_len=context_len,\n",
        "\t\t\tn_heads=n_heads,\n",
        "\t\t\tdrop_p=dropout_p,\n",
        "\t\t).to(device)\n",
        "  \n",
        "optimizer = torch.optim.AdamW(\n",
        "\t\t\t\t\tmodel.parameters(), \n",
        "\t\t\t\t\tlr=lr, \n",
        "\t\t\t\t\tweight_decay=wt_decay\n",
        "\t\t\t\t)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
        "\t\toptimizer,\n",
        "\t\tlambda steps: min((steps+1)/warmup_steps, 1)\n",
        "\t)\n",
        "\n",
        "max_d4rl_score = -1.0\n",
        "total_updates = 0\n",
        "\n",
        "for i_train_iter in range(max_train_iters):\n",
        "\n",
        "\tlog_action_losses = []\t\n",
        "\tmodel.train()\n",
        " \n",
        "\tfor _ in range(num_updates_per_iter):\n",
        "\t\ttry:\n",
        "\t\t\ttimesteps, states, actions, returns_to_go, traj_mask = next(data_iter)\n",
        "\t\texcept StopIteration:\n",
        "\t\t\tdata_iter = iter(traj_data_loader)\n",
        "\t\t\ttimesteps, states, actions, returns_to_go, traj_mask = next(data_iter)\n",
        "\n",
        "\t\ttimesteps = timesteps.to(device)\t# B x T\n",
        "\t\tstates = states.to(device)\t\t\t# B x T x state_dim\n",
        "\t\tactions = actions.to(device)\t\t# B x T x act_dim\n",
        "\t\treturns_to_go = returns_to_go.to(device).unsqueeze(dim=-1) # B x T x 1\n",
        "\t\ttraj_mask = traj_mask.to(device)\t# B x T\n",
        "\n",
        "\t\tstates=states.to(torch.float32)\n",
        "\t\tactions=actions.to(torch.float32)\n",
        "\t\treturns_to_go=returns_to_go.to(torch.float32)\n",
        "\n",
        "\t\taction_target = torch.clone(actions).detach().to(device)\n",
        "\t\n",
        "\t\tstate_preds, action_preds, return_preds = model.forward(\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\ttimesteps=timesteps,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tstates=states,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tactions=actions,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\treturns_to_go=returns_to_go\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t)\n",
        "\n",
        "\t\t# only consider non padded elements\n",
        "\t\taction_preds = action_preds.view(-1, act_dim)[traj_mask.view(-1,) > 0]\n",
        "\t\taction_target = action_target.view(-1, act_dim)[traj_mask.view(-1,) > 0]\n",
        "\n",
        "\t\taction_loss = F.mse_loss(action_preds, action_target, reduction='mean')\n",
        "\n",
        "\t\toptimizer.zero_grad()\n",
        "\t\taction_loss.backward()\n",
        "\t\ttorch.nn.utils.clip_grad_norm_(model.parameters(), 0.25)\n",
        "\t\toptimizer.step()\n",
        "\t\tscheduler.step()\n",
        "\n",
        "\t\tlog_action_losses.append(action_loss.detach().cpu().item())\n",
        "\n",
        "\t# evaluate on env\n",
        "\tresults = evaluate_on_env(num_LTLs, feature_idx, c_list, model, device, context_len, env, rtg_target, rtg_scale,\n",
        "\t                        num_eval_ep, max_eval_ep_len, state_mean, state_std, \n",
        "\t\t\t\t\t\t\t)\n",
        "\teval_avg_reward = results['eval/avg_reward']\n",
        "\teval_avg_ep_len = results['eval/avg_ep_len']\n",
        "\teval_d4rl_score = 10#get_d4rl_normalized_score(results['eval/avg_reward'], env_name) * 100\n",
        "\n",
        "\tmean_action_loss = np.mean(log_action_losses)\n",
        "\ttime_elapsed = str(datetime.now().replace(microsecond=0) - start_time)\n",
        "\n",
        "\ttotal_updates += num_updates_per_iter\n",
        "\n",
        "\tlog_str = (\"=\" * 60 + '\\n' +\n",
        "\t\t\t\"time elapsed: \" + time_elapsed  + '\\n' +\n",
        "\t\t\t\"num of updates: \" + str(total_updates) + '\\n' +\n",
        "\t\t\t\"action loss: \" +  format(mean_action_loss, \".5f\") + '\\n' +\n",
        "\t\t\t\"eval avg reward: \" + format(eval_avg_reward, \".5f\") + '\\n' +\n",
        "\t\t\t\"eval avg ep len: \" + format(eval_avg_ep_len, \".5f\") + '\\n' +\n",
        "\t\t\t\"eval d4rl score: \" + format(eval_d4rl_score, \".5f\")\n",
        "\t\t\t)\n",
        "\n",
        "\tprint(log_str)\n",
        "\n",
        "\tlog_data = [time_elapsed, total_updates, mean_action_loss,\n",
        "\t\t\t\teval_avg_reward, eval_avg_ep_len,\n",
        "\t\t\t\teval_d4rl_score]\n",
        "\n",
        "\tcsv_writer.writerow(log_data)\n",
        "\t\n",
        "\t# save model\n",
        "\tprint(\"max d4rl score: \" + format(max_d4rl_score, \".5f\"))\n",
        "\tif eval_d4rl_score >= max_d4rl_score:\n",
        "\t\tprint(\"saving max d4rl score model at: \" + save_best_model_path)\n",
        "\t\ttorch.save(model.state_dict(), save_best_model_path)\n",
        "\t\tmax_d4rl_score = eval_d4rl_score\n",
        "\n",
        "\tprint(\"saving current model at: \" + save_model_path)\n",
        "\ttorch.save(model.state_dict(), save_model_path)\n",
        "\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"finished training!\")\n",
        "print(\"=\" * 60)\n",
        "end_time = datetime.now().replace(microsecond=0)\n",
        "time_elapsed = str(end_time - start_time)\n",
        "end_time_str = end_time.strftime(\"%y-%m-%d-%H-%M-%S\")\n",
        "print(\"started training at: \" + start_time_str)\n",
        "print(\"finished training at: \" + end_time_str)\n",
        "print(\"total training time: \" + time_elapsed)\n",
        "print(\"max d4rl score: \" + format(max_d4rl_score, \".5f\"))\n",
        "print(\"saved max d4rl score model at: \" + save_best_model_path)\n",
        "print(\"saved last updated model at: \" + save_model_path)\n",
        "print(\"=\" * 60)\n",
        "\n",
        "\n",
        "files.download(save_best_model_path)\n",
        "print(f\"best model downloaded locally\")\n",
        "files.download(save_model_path)\n",
        "print(f\"most recent model downloaded locally\")\n",
        "\n",
        "#csv_writer.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eosqWqRRJLsZ"
      },
      "source": [
        "# test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4-WPlC1VR3q",
        "outputId": "a8da7f26-3c33-42cb-ffe1-b2d2aa0ff37b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/root/.mujoco/mujoco200/bin\n",
            "model loaded from: ./dt_runs/dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\n",
            "LTL success rate for bin (1.0, 11.0) (of 58 total cases): 1.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 42 total cases): 0.000\n",
            "{'eval/avg_reward': 4962.064865402578, 'eval/avg_ep_len': 1000.0}\n",
            "normalized d4rl score:  42.22447246429616\n",
            "============================================================\n",
            "evaluated on env: HalfCheetah-v3\n",
            "total num of checkpoints evaluated: 1\n",
            "d4rl score mean: 42.22447\n",
            "d4rl score std: 0.00000\n",
            "d4rl score var: 0.00000\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# set mujoco env path if not already set\n",
        "%env LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/root/.mujoco/mujoco200/bin\n",
        "\n",
        "\n",
        "eval_dataset = \"medium\"\t\t# medium / medium-replay / medium-expert\n",
        "eval_rtg_scale = 1000\t\t# normalize returns to go\n",
        "\n",
        "# eval_env_name = \"Walker2d-v3\"\n",
        "# eval_rtg_target = 5000\n",
        "# eval_env_d4rl_name = f'walker2d-{eval_dataset}-v2'\n",
        "\n",
        "eval_env_name = 'HalfCheetah-v3'\n",
        "eval_rtg_target = 2000\n",
        "eval_env_d4rl_name = f'halfcheetah-medium-expert-v2'\n",
        "\n",
        "num_test_eval_ep = 100\t\t\t# num of evaluation episodes\n",
        "eval_max_eval_ep_len = 1000\t\t# max len of one episode\n",
        "\n",
        "\n",
        "context_len = 20        # K in decision transformer\n",
        "n_blocks = 3            # num of transformer blocks\n",
        "embed_dim = 128         # embedding (hidden) dim of transformer\n",
        "n_heads = 1             # num of transformer heads\n",
        "dropout_p = 0.1         # dropout probability\n",
        "\n",
        "eval_chk_pt_dir = \"./dt_runs/\"\n",
        "\n",
        "eval_chk_pt_name = \"dt_halfcheetah-medium-expert-v2_model_23-05-07-23-04-28_best.pt\"\n",
        "eval_chk_pt_list = [eval_chk_pt_name]\n",
        "\n",
        "env_data_stats = get_d4rl_dataset_stats(eval_env_d4rl_name)\n",
        "eval_state_mean = np.array(env_data_stats['state_mean'])\n",
        "eval_state_std = np.array(env_data_stats['state_std'])\n",
        "\n",
        "eval_env = gym.make(eval_env_name)\n",
        "\n",
        "state_dim = eval_env.observation_space.shape[0] + num_LTLs\n",
        "act_dim = eval_env.action_space.shape[0]\n",
        "\n",
        "all_scores = []\n",
        "\n",
        "for eval_chk_pt_name in eval_chk_pt_list:\n",
        "\n",
        "\teval_model = DecisionTransformer(\n",
        "\t\t\t\tstate_dim=state_dim,\n",
        "\t\t\t\tact_dim=act_dim,\n",
        "\t\t\t\tn_blocks=n_blocks,\n",
        "\t\t\t\th_dim=embed_dim,\n",
        "\t\t\t\tcontext_len=context_len,\n",
        "\t\t\t\tn_heads=n_heads,\n",
        "\t\t\t\tdrop_p=dropout_p,\n",
        "\t\t\t).to(device)\n",
        "\n",
        "\n",
        "\teval_chk_pt_path = os.path.join(eval_chk_pt_dir, eval_chk_pt_name)\n",
        "\n",
        "\t# load checkpoint\n",
        "\teval_model.load_state_dict(torch.load(eval_chk_pt_path, map_location=device))\n",
        "\n",
        "\tprint(\"model loaded from: \" + eval_chk_pt_path)\n",
        "\n",
        "\t# evaluate on env\n",
        "\tresults = evaluate_on_env(num_LTLs, feature_idx, c_list, eval_model, device, context_len,\n",
        "\t\t\t\t\t\t\teval_env, eval_rtg_target, eval_rtg_scale,\n",
        "\t\t\t\t\t\t\tnum_test_eval_ep, eval_max_eval_ep_len,\n",
        "\t\t\t\t\t\t\teval_state_mean, eval_state_std)\n",
        "\tprint(results)\n",
        "\n",
        "\tnorm_score = get_d4rl_normalized_score(results['eval/avg_reward'], eval_env_name) * 100\n",
        "\tprint(\"normalized d4rl score: \", norm_score)\n",
        "\n",
        "\tall_scores.append(norm_score)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "all_scores = np.array(all_scores)\n",
        "print(\"evaluated on env: \" + eval_env_name)\n",
        "print(\"total num of checkpoints evaluated: \" + str(len(eval_chk_pt_list)))\n",
        "print(\"d4rl score mean: \" + format(all_scores.mean(), \".5f\"))\n",
        "print(\"d4rl score std: \" + format(all_scores.std(), \".5f\"))\n",
        "print(\"d4rl score var: \" + format(all_scores.var(), \".5f\"))\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxcJqnb1Him4"
      },
      "source": [
        "## render env\n",
        "\n",
        "\n",
        "\n",
        "*   saves mp4 video of env frames and plays it in notebook\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hdf_bea2hiRs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "437dc3de-0623-49d4-d344-fc27fa395851"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting colabgymrender\n",
            "  Downloading colabgymrender-1.1.0.tar.gz (3.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (from colabgymrender) (1.0.3)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy->colabgymrender) (0.4.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from moviepy->colabgymrender) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy->colabgymrender) (2.27.1)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy->colabgymrender) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy->colabgymrender) (2.25.1)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy->colabgymrender) (0.1.10)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy->colabgymrender) (4.65.0)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy->colabgymrender) (8.4.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy->colabgymrender) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy->colabgymrender) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy->colabgymrender) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy->colabgymrender) (1.26.15)\n",
            "Building wheels for collected packages: colabgymrender\n",
            "  Building wheel for colabgymrender (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for colabgymrender: filename=colabgymrender-1.1.0-py3-none-any.whl size=3130 sha256=e1400057646d1955e0aaec94665455f4b1d5ae8503bd109007350abe74ce5b52\n",
            "  Stored in directory: /root/.cache/pip/wheels/13/62/63/7b3acfb684dd3d665d7fc1d213427b136205a222389767e295\n",
            "Successfully built colabgymrender\n",
            "Installing collected packages: colabgymrender\n",
            "Successfully installed colabgymrender-1.1.0\n"
          ]
        }
      ],
      "source": [
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
        "!pip install -U colabgymrender"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-RpNwa0hiPR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8023df94-382d-40bb-b761-501df38e5b60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/moviepy/video/fx/painting.py:7: DeprecationWarning: Please use `sobel` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n",
            "  from scipy.ndimage.filters import sobel\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LTL success rate for bin (1.0, 11.0) (of 0 total cases): 0.000\n",
            "LTL success rate for bin (11.0, 21.0) (of 1 total cases): 0.000\n",
            "{'eval/avg_reward': 5321.349323485767, 'eval/avg_ep_len': 1000.0}\n",
            "normalized d4rl score:  45.11838530633676\n"
          ]
        }
      ],
      "source": [
        "from colabgymrender.recorder import Recorder\n",
        "\n",
        "num_test_eval_ep = 1\n",
        "eval_max_ep_len = 1000\n",
        "\n",
        "\n",
        "directory = \"./render_video\"\n",
        "eval_env = Recorder(eval_env, directory)\n",
        "\n",
        "results = evaluate_on_env(num_LTLs, feature_idx, c_list, eval_model, device, context_len, \n",
        "                        eval_env, eval_rtg_target, eval_rtg_scale, \n",
        "                        num_test_eval_ep, eval_max_ep_len,\n",
        "\t\t\t\t\t\teval_state_mean, eval_state_std)\n",
        "print(results)\n",
        "\n",
        "norm_score = get_d4rl_normalized_score(results['eval/avg_reward'], eval_env_name) * 100\n",
        "print(\"normalized d4rl score: \", norm_score)\n",
        "\n",
        "#eval_env.play()\n",
        "\n",
        "eval_env.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjBsdz9mKbZg"
      },
      "source": [
        "# plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WM69ti2KaRN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "4d6e0921-47fd-4039-bc90-a72f9df9442d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dt_runs/dt_halfcheetah-medium-expert-v2_log_23-05-07-23-04-28.csv (200, 6)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "env_d4rl_name = 'halfcheetah-medium-expert-v2'\n",
        "\n",
        "log_dir = 'dt_runs/'\n",
        "\n",
        "x_key = \"num_updates\"\n",
        "y_key = \"eval_d4rl_score\"\n",
        "y_smoothing_win = 5\n",
        "plot_avg = False\n",
        "save_fig = False\n",
        "\n",
        "if plot_avg:\n",
        "    save_fig_path = env_d4rl_name + \"_avg.png\"\n",
        "else:\n",
        "    save_fig_path = env_d4rl_name + \".png\"\n",
        "\n",
        "\n",
        "all_files = glob.glob(log_dir + f'/dt_{env_d4rl_name}*.csv')\n",
        "\n",
        "ax = plt.gca()\n",
        "ax.set_title(env_d4rl_name)\n",
        "\n",
        "if plot_avg:\n",
        "    name_list = []\n",
        "    df_list = []\n",
        "    for filename in all_files:\n",
        "        frame = pd.read_csv(filename, index_col=None, header=0)\n",
        "        print(filename, frame.shape)\n",
        "        frame['y_smooth'] = frame[y_key].rolling(window=y_smoothing_win).mean() \n",
        "        df_list.append(frame)\n",
        "    \n",
        "    \n",
        "    df_concat = pd.concat(df_list)\n",
        "    df_concat_groupby = df_concat.groupby(df_concat.index)\n",
        "    data_avg = df_concat_groupby.mean()\n",
        "\n",
        "    data_avg.plot(x=x_key, y='y_smooth', ax=ax)\n",
        "    \n",
        "    ax.set_xlabel(x_key)\n",
        "    ax.set_ylabel(y_key)\n",
        "    ax.legend(['avg of all runs'], loc='lower right')\n",
        "    \n",
        "    if save_fig:\n",
        "        plt.savefig(save_fig_path)\n",
        "        \n",
        "    plt.show()\n",
        "    \n",
        "    \n",
        "else:\n",
        "    name_list = []\n",
        "    for filename in all_files:\n",
        "        frame = pd.read_csv(filename, index_col=None, header=0)\n",
        "        print(filename, frame.shape)\n",
        "        frame['y_smooth'] = frame[y_key].rolling(window=y_smoothing_win).mean()\n",
        "        frame.plot(x=x_key, y='y_smooth', ax=ax)\n",
        "        name_list.append(filename.split('/')[-1])\n",
        "    \n",
        "    ax.set_xlabel(x_key)\n",
        "    ax.set_ylabel(y_key)\n",
        "    ax.legend(name_list, loc='lower right')\n",
        "    \n",
        "    if save_fig:\n",
        "        plt.savefig(save_fig_path)\n",
        "    \n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}